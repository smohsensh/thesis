\section{کارهای پیشین}\label{review}
یک نحوه مدل‌سازی  یادگیری از صفر، آن طور که در \cite{hinton09} بیان شده، تبدیل آن به دو زیر مسئله است. مسئله اول یادگیری یک نگاشت از مجموعه تصاویر به یک فضای میانی که توصیف کلاس‌ها در آن قرار دارند و مسئله دوم یادگرفتن یک دسته‌بند که اعضای فضای میانی را به برچسب‌ها دسته‌بندی کند. در این نحوه مدل‌سازی فضای معنایی توصیف‌ها داده‌شده فرض می‌شود. این درحالی‌ست که بسیاری از اوقات توصیف‌ها به صورت خام قابل استفاده نیستند. برای مثال وقتی اطلاع جانبی از نوع متن است را در نظر بگیرید، فضای متون فضایی با بعد بسیار بالاست و لازم است که خود به یک فضای میانی نگاشته شود. یادگیری نگاشت از توصیف‌ها به فضای میانی ممکن است به صورت هم‌زمان و اشتراک بعضی پارامترها با سایر قسمت‌های مدل یادگرفته شود؛ در نتیجه لازم است یادگیری این نگاشت را هم جزو چارچوب ارائه شده در نظر بگیریم. در این نحوه‌ی مدل‌سازی یک چارچوب کلی برای بسیاری از روش‌های ارائه شده در یادگیری از صفر است. البته روش‌هایی هم وجود دارند که در این چارچوب نگنجند. در این بخش، با توجه به فراگیری این چارچوب ابتدا توصیف رسمی و معرفی نمادگذاری برای آن ارائه می‌شود. سپس روش‌های ذیل این چارچوب را مرور کرده و در پایان سایر روش‌ها را بیان می‌کنیم. 
 
 
 \subsection{نماد‌گذاری} \label{notaion}
 تصاویر را با 
 $x \in \mathbb{R}^d$
 نشان می‌دهیم که $d$ ابعاد داده را نشان می‌دهد. توصیف‌ها را با 
 $ c \in \mathbb{R}^a$
 نمایش می‌دهیم. $a$ ابعاد توصیف‌هاست. مجموعه دسته‌های دیده‌شده را با  $ \mathcal{S}$ و دسته‌های دیده‌نشده را با $ \mathcal{U}$ و مجموعه کل برچسب‌ها را با $ \mathcal{Y}$ 
 نشان می‌دهیم که
 $ \mathcal{Y} =  \mathcal{U} \cup \mathcal{S} $.
 همچنین   $s$ و $u$ به ترتیب تعداد هر کدام از دسته‌ها را نشان می‌دهد. $c^y$ که    $ y \in \mathcal{U} \cup \mathcal{S} $ بردار توصیف کلاس $y$ را نشان می‌دهد.
   
    فرض می‌کنیم در زمان آموزش $N_s$ تصویر از دسته‌های دیده شده به همراه برچسب و  توصیف دسته‌ها موجود است. 
 $X_s \in \mathbb{R}^{N_s \times d}$
  مجموعه تصاویر، $Y$ بردار برچسب‌ها و 
  $C_s \in \mathbb{R}^{s \times a}$
 مجموعه توصیف‌های دسته‌های آموزش ست. $X_u$ و $C_u$ بطور مشابه برای دسته‌های آزمون تعریف می‌شوند. 
 
 فضای میانی را با $ \mathcal{M} $ و ضرب داخلی آن را با  $\langle ., . \rangle $ نشان می‌دهیم. 
 $ \pi : \mathbb{R}^d \to \mathcal{M}$ 
 و
 $ \psi : \mathbb{R}^a \to \mathcal{M}$ 
نگاشت‌هایی از فضای تصاویر و توصیفات به این فضا هستند. 
یادگیری نگاشت‌های  $\pi$ و $\psi$ ممکن است به صورت مستقل از هم انجام شود یا اینکه هم‌زمان یادگرفته شوند. در نهایت باید دسته‌بندی از  $ \mathcal{M} $ به برچسب‌ها داشته باشیم:
 $ \phi : \mathcal{M} \to \mathcal{Y}$.
 در خیلی از موارد دسته‌بندی را تنها روی دسته‌های آزمون در نظر می‌گیریم، یعنی برد $\phi$ تنها $ \mathcal{U}$ را شامل می‌شود نه تمام برچسب‌ها را.
در ساده‌ترین حالت $\phi$ یک دسته‌بند نزدیک‌ترین همسایه در نظر گرفته می‌شود، یعنی برچسب نمونه آزمون  $x$ با رابطه \ref{inner} پیش‌بینی خواهد شد:
\begin{equation}\label{inner}
y^* = \argmax_{y \in \mathcal{U}} \langle \pi(x), \psi(c^y) \rangle
\end{equation}
البته این انتخاب برای  $\phi$ محدودیت‌های شناخته شده‌ای دارد. از جمله این که تمامی ابعاد از اهمیت یکسانی برخوردار هستند، درحالی‌که ممکن است بعض ویژگی‌ها قابلیت جداسازی بهتری داشته باشند. 

چارچوب فوق را می‌توان به روش‌های احتمالی هم تعمیم داد، به این صورت که $\pi$ و $\psi$ به صورت توزیع‌های احتمال شرطی تغییر پیدا می‌کنند. این تعمیم به صورت دقیق‌تر در بخش \ref{prob} بررسی خواهد شد. 


\subsubsection{کران خطا}\label{bound}
تعریف و فروض یادگیری از صفر با حالت معمول دسته‌بندی متفاوت است. در نتیجه کران‌هایی که امکان‌پذیر بودن دسته‌بندی را با استفاده تعداد محدودی نمونه ضمانت می‌کنند را نمی‌توان در اینجا به کار بست. برای ارائه کران‌های خطای دسته‌بندی از صفر فرض‌های ساده‌کننده‌ای به مسئله اضافه شده است. برای این منظور فرض می‌شود که یادگیری نگاشت $\psi$ مستقل از $\pi$ انجام شده و رابطه بین توصیف‌ها و برچسب دسته‌ها رابطه‌ای یک به یک است. با این دو فرض می‌توان $\psi(c^y) $ را \emph{ امضای}  دسته‌ی $y$ نامید. 

در \cite{hinton09} با فرض دودویی بودن هر بعد از امضای دسته‌ها، کرانی بر اساس فاصله همینگ 
\LTRfootnote{Hamming}
میان امضای دسته‌ی صحیح و مقدار پیش‌بینی شده ارائه می‌شود. در \cite{emb} از نتایج مشابه در حوزه تطبیق دامنه برای کران‌دار کردن خطا استفاده می‌شود. در این جا کران ارائه شده بر اساس تفاوت توزیع‌های داده‌های آموزش و آزمون است. در آن نوشتار راهی برای تخمین تفاوت این دو توزیع در حالت کلی ارائه نمی‌شود. تنها به دو حالت حدی اشاره می‌شود که در صورت یکسان بودن توزیع‌ها، کران ارائه شده همان کران مشهور VC \cite{vapnik} خواهد بود. هم‌چنین درحالیکه امضای کلاس‌ها بر هم کاملا عمود باشد کران برای احتمال خطا بزرگتر از یک شده و اطلاعاتی در بر ندارد. 
\subsection{پیش‌بینی ویژگی}
همان‌طور که در بخش \ref{intro} اشاره شد، بردار ویژگی مرسوم‌ترین نوع توصیف کلاس‌هاست. نخستین کارها روی یادگیری از صفر در بینایی ماشین \cite{lampert09, farhadi09}،
روش پیش‌بینی مستقیم ویژگی‌ها را پیشنهاد داده‌اند. در این حالت سعی می‌شود بردار ویژگی از روی تصویر ورودی بازسازی شود. آن‌گاه از میان دسته‌های دیده نشده، دسته‌ای که بردار ویژگی‌اش بیشترین مشابهت را با بردار پیش‌بینی شده دارد به عنوان برچسب معرفی می‌شود. با ادبیات چارچوب معرفی شده این روش را این گونه توصیف می‌شود که فضای میانی  $ \mathcal{M} $ همان فضای بردار ویژگی در نظر گرفته شده است در نتیجه نگاشت $\psi$ نگاشت همانی است و هدف تنها یادگرفتن نگاشت $\pi$ است. اهمیت این روش‌ها از یک طرف بخاطر داده‌های بسیاری است که با فراداده‌ها \LTRfootnote{Meta-data} و دنبالک‌ها \LTRfootnote{Tag} همراه شده‌اند که به صورت بردار ویژگی قابل مدل‌سازی هستند. دلیل دیگری برای اهمیت این روش‌ها این است که در مواردی هم که توصیف‌ها از نوع بردار ویژگی نیستند، ابتدا $\psi$ به صورت مستقل یادگرفته می‌شود و بعد از آن با در نظر گرفتن   $ \psi(c^x) $ بعنوان بردار ویژگی کلاس‌ها مسئله به حالت مورد بحث این بخش تبدیل خواهد شد.  

 
 اگر ویژگی‌ها دودویی باشند. این مسئله را می‌توان نوعی دسته‌بندی چند برچسبی \LTRfootnote{Mulit-label Classification} دانست که مدت زیادی است در حوزه یادگیری ماشین مورد مطالعه قرار گرفته است \cite{multilabel}. البته دسته‌بندی چندبرچسبی با یادگیری از صفر از طریق پیش‌بینی ویژگی تفاوت‌هایی دارد. در اولی خروجی الگوریتم یک بردارد ویژگی است و ترکیب‌های بسیار زیادی از مقادیر برای آن مجاز هستند، در دومی خروجی نهایتا یک برچسب از کلاس‌های دیده نشده است و بردار ویژگی یک مقدار میانی برای رسیدن به این خروجی است. هم‌چنین همه ترکیب‌ها از ویژگی‌ها مجاز نیستند و تنها به تعداد دسته‌ها بردار ویژگی معتبر وجود دارد. در صورتی که ویژگی‌ها پیوسته باشند مسئله پیش‌بینی آن‌ها می‌تواند به صورت یک مسئله رگرسیون در نظر گرفته شود که برای در نظر گرفتن ارتباط ویژگی‌های مختلف باید با مدل‌های 
 رگرسیون ساختاریافته  \cite{elements} حل شود. روش‌های معمول رگرسیون مانند فرآیند گاوسی هر ویژگی را به صورت جداگانه یاد گرفته و ارتباط میان ابعاد در نظر گرفته نخواهد شد \cite{mohamed13}. مانند حالت دودویی مشکل دیگر تفاوت اساسی این مسئله با یادگیری از صفر است. در این مسئله به دنبال خطای کمتر در ویژگی‌های پیش‌بینی شده هستیم درحالی‌که در مسئله یادگیری از صفر این خطا اهمیتی ندارد و الگوریتم با دقت برچسب‌گذاری سنجیده می‌شود. 
\subsubsection{روش‌های احتمالی}\label{prob}

 
یکی از نخستین روش‌های پیش‌بینی ویژگی در \cite{lampert09} ارائه شده است. فرض کنید در زمان آموزش نمونه‌های 
$ \{ (x_i, y_i) \}_{i=1}^{N_s} $ 
به همراه بردار ویژگی دسته‌های آموزش  $C_y$ در اختیار قرار گرفته است. در نسخه اول این روش که DAP نام دارد استفاده از داده‌های آزمون تنها به صورت یادگیری دسته‌بندهایی برای هر یک از ویژگی‌هاست. این یادگیری با فرض استقلال ابعاد ویژگی‌ها انجام می‌شود، یعنی 
$P(c|x) = \prod_{i=1}^d P(c_i|x) $.
و هر یک از $P(c_i|x) $ها با یک رگرسیون منطقی 
\LTRfootnote{Logistic Regression}
روی کل داده‌ها (مستقل از برچسب آن‌ها) تخمین زده می‌شود. همچنین احتمال پیشین وقوع هر یک ویژگی‌ها، $ P(c_i)$، به صورت تجربی با توجه به تعداد وقوع تعیین می‌شود. در نهایت احتمال پسین هرکدام از برچسب‌های آزمون $u \in \mathcal{U}$ از این رابطه بدست می‌آید:
\begin{equation}
P(u | x ) = \sum_{c} P(u | c)P(c|x) = \frac{P(u)}{P(c^u)} \prod_{i=1}^d P(c^u_i|x) \propto \prod_{i=1}^d \frac{P(c^u_i|x)}{P(c^u_i)}
\end{equation}
در نسخه دیگر این روش که IAP نام دارد تخمین  $P(c_i|x) $ تغییر داده می‌شود به این صورت که ابتدا یک دسته‌بند چند دسته‌ای یعنی $P(y_k |x)$ روی داده‌ها یاد گرفته می‌شود و سپس رابطه ویژگی‌ها و برچسب‌ها به صورت قطعی مدل می‌شود. در نهایت خواهیم داشت:
\begin{equation}
P(c_i | x) = \sum_{k=1}^s P(y_k | x) \mathbb{I}(c_i = c^{y_k}_i)
\end{equation}
که $ \mathbb{I}(p) $ وقتی که شرط $p$ برقرار باشد برابر $1$ و در غیر این صورت صفر است. 

علاوه بر این دو نسخه، این روش به حالت‌های دیگری هم توسعه داده شده است. برای مثال در \cite{suzuki14} وزن‌دهی متفاوت برای مدل‌سازی اهمیت هر کدام از ویژگی‌ها به مدل اضافه شده است. این روش دو کمبود مهم دارد، اول این که فرض استقلال میان ویژگی‌ها بسیار غیر واقعی است. برای مثال ویژگی‌های بصری خاک و صحرا وابستگی واضحی وجود دارد. مشکل دوم این است که  یادگیری دسته‌بندها برای هر ویژگی بدون توجه به این است که از خروجی آن در دسته‌بندی دیگری استفاده می‌شود و معیار ارزیابی عمل‌کرد خطای دسته‌بند دوم است و خطای پیش‌بینی ویژگی‌ها به طور مستقیم اهمیت ندارد. نویسندگان \cite{ ajoint11} برای حل این مشکل پیشنهاد می‌کنن فرض یک به یک بودن نگاشت بین بردارهای ویژگی و برچسب‌ها را در نظر نگیریم و به عبارت دیگر  دسته‌بند $\phi$ معرفی شده در بخش
 \ref{ notation} 
  یادگرفته شود. پیش‌بینی ویژگی‌ها مانند مدل DAP با رگرسیون منطقی انجام می‌شود با این تفاوت که یادگیری پارامترهای آن‌ها و  $\phi$ به صورت مشترک انجام می‌شود. $\phi$ یک نگاشت خطی در نظر گرفته می‌شود: 
  $\phi(\pi(x)) = R\pi(x) $. 
 دو محدودیت روی مقادیر R اعمال می‌شود. یک محدویت سطری و یک محدودیت ستونی. محدودیت سطری مانع از این می‌شود که فاصله همینگ سطرها از حدی کمتر بشود. دقت کنید که در یک دسته‌بند خطی به شکل بالا، هر سطر مانند نماینده از یک دسته است که میزان شباهت با آن میزان تعلق به آن دسته را می‌سنجد. در نتیجه این محدودیت تضمین می‌کند که بردار ویژگی نماینده هر دسته با دسته‌های دیگر متفاوت باشد. محدودیت ستونی یک مقدار حداکثری برای همبستگی میان ستون‌ها در نظر می‌گیرد تا به این صورت اطلاعات تکراری در ویژگی‌ها وجود نداشته باشد. نویسندگان این مقاله استدلال می‌کنند که با این دو محدودیت باعث حذف ویژگی‌های تکراری و ویژگی‌های غیر بصری (مانند بدبو بودن) خواهد شد.
 
نویسندگان \cite{ topicmodel} برای در نظر گرفتن ارتباط بین ویژگی‌ها و ارتباط ویژگی‌ها با برچسب نهایی روش‌های مدل‌سازی مباحث\LTRfootnote{  Topic Modeling} را از حوزه یادگیری در متن اقتباس می‌کنند. همچنین  نویسندگان \cite{ unified13} برای این کار یک چارچوب بر اساس مدل‌های گرافی احتمال معرفی می‌کنند. در این چارچوب یک شبکه بیزی\LTRfootnote{  Baysian Network}  برای مدل کردن این روابط در نظر گرفته می‌شود که ساختار آن با کمک روش‌های یادگیری ساختار 
\LTRfootnote{Structure Learning}
شناخته می‌شود. 

\subsubsection{نگاشت‌های خطی}\label{linear}
چند روش اخیر وجود دارد که علی‌رغم ساده بودن نتایج بهتری از روش‌های قبلی کسب کرده‌اند. در این روش‌ها  نگاشت $\psi$ همانی، دسته‌بند $\psi$ دسته‌بند نزدیک‌ترین همسایه و نگاشت $\pi$ خطی $(\pi(x) = xW$ در نظر گرفته شده‌اند. اما معرفی توابع هزینه یا جمله‌های منظم‌سازی 
\LTRfootnote{Regularization  Term}
هوشمندانه‌تر باعث شده که نتایج بهتری به دست بیاورند. یکی از این روش‌ها که در \cite{ akata13} معرفی شده، تابع هزینه‌ای ارائه می‌دهد که هم خطای دسته‌بندی، هم خطای پیش‌بینی ویژگی‌ها را در نظر می‌گیرد. این تابع هزینه چنین شکلی دارد:
\begin{align}
L(W) = \frac{1}{N_s} \sum_{n=1}^{N_s} \lambda_{r_\Delta (x_n, y_n)} \sum_{y \in \mathcal{Y}} \max (0, \mathit{l}(x_n, y_n, y) ) \\
\mathit{l}(x_n,y_n,y) = \mathbb{I}(y \neq y_n) + x_nWc_y - x_nWc_{y_n}
\end{align}
که در آن $ r_\Delta (x_n, y_n) =  \sum_{y \in \mathcal{Y}} \mathbb{I}(\mathit{l}(x_n, y_n, y)  > 0) $ و $\lambda_k$ یک تابع نزولی از $k$ است. این تابع، پیش‌بینی اشتباه ویژگی‌ها را  این گونه جریمه می‌کند که به ازای برچسب نادرستی که رتبه بالاتری از برچسب صحیح در دسته‌بندی دریافت کرده، جریمه‌ای متناسب با امتیاز برچسب ناصحیح در نظر گرفته می‌شود.ضریب نزولی $\lambda_k$ میزان جریمه را برای برچسب‌های غلط در رتبه‌های بالا بیشتر در نظر می‌گیرد.

یک روش دیگر که در \cite{ emb15} ارائه شده، نگاشت‌های مشابهی را استفاده می‌کند. همچنین تابع هزینه آن شکل ساده نرم ۲ را دارد. مسئله‌ی بهینه‌سازی تعریف شده به این شکل است:
\begin{equation} 
\minimize_{W \in \mathbb{R}^{d \times a}} \normf{X_s WC_s} + \Omega(W) \label{embopt}
\end{equation}
که $\Omega(W)$ یک جمله منظم‌سازی است که به این صورت تعریف می‌شود:
\begin{equation} \label{embreg}
 \Omega(W;X_s, C_s) = \gamma \normf{WC_s} + \lambda \normf{XW} + \beta \normf{W} 
\end{equation}
که تابع هزینه فوق تنها دسته‌بندی اشتباه را جریمه می‌کند. مناسب نبودن تابع هزینه نرم ۲ برای خطای دسته‌بندی مسئله‌ای شناخته شده در یادگیری ماشین است و عمل‌کرد خوب این تابع در این روش شاید در نگاه اول عجیب بنظر برسد. اگر در جمله منظم‌سازی تعریف شده دقت کنیم این مسئله روشن‌تر خواهد شد. تابع هزینه نرم ۲ به این علت که حتی دسته‌بندی‌های صحیح را اگر مقداری غیر از مقدار تعیین شده (معمولا یک) داشته باشند، به اندازه فاصله‌شان از این مقدار جریمه می‌کنید. اما جمله منظم‌سازی تعریف شده اصولا مانع بزرگ شدن مقدار پیش‌بینی شده خواهد شد. جمله اول در معادله \eqref{ embreg} را می‌توان اندازه بردار تصویر متوسط برای هر دسته دانست. جمله دوم مقدار بردار ویژگی پیش‌بینی شده برای هر دسته است و جمله سوم هم که یک جمله معمول است که پارامترهای نگاشت را کنترل می‌کند. در زمان آزمون برای نمونه $x$ مقدار $xWC_u$ را محاسبه کرده و دسته‌ای که درایه‌ی متناظرش بیشترین مقدار را دارد به عنوان پیش‌بینی معرفی می‌کنیم. یک ویژگی این روش این است که با انتخاب $ \beta = \gamma \lambda$ در معادله \eqref{ embreg } بهینه‌سازی معادله \eqref{ embopt} جواب بسته خواهد داشت؛ در نتیجه زمان اجرای این روش بسیار کمتر از سایر روش‌هایی است که مرور شد. 

یک روش خطی دیگر که مستقیم از ویژگی‌ها استفاده نمی‌کند کاری است که در \cite{ devise} معرفی شده. این روش از تنها از نام هر کلاس به عنوان توصیف بهره می‌برد. با توجه به این در این روش نام‌ها مستقل از اطلاعات دیگر مسئله به بردارهایی نگاشته می‌شوند، بردارهای حاصل را می‌توان مانند بردار ویژگی در سایر مسائل به حساب آورد؛ در نتیجه این روش را ذیل عنوان پیش‌بینی ویژگی مرور می‌کنیم. این روش ابتدا برای بدست‌آوردن بردارهای مربوط به نام‌ها از مدل مشهور 
\lr{ word2vec}  \cite{ word2vec} 
با پیش‌آموزش روی مقالات ویکی‌پدیای انگلیسی استفاده می‌کند. این روش هم‌چنین برای ویژگی‌های تصویر از شبکه عصبی برنده چالش
\lr{ ILSVRC 2012}
استفاده می‌کند. \footnote{ استفاده از مقادیر نورون‌های لایه چگال اول شبکه‌های عصبی به عنوان ویژگی‌های بصری در بسیاری از روش‌های دیگر نیز صورت گرفته است؛ در نتیجه این قسمت جزوی از نگاشت $\pi$ در نظر گرفته نمی‌شود، بلکه این مقادیر را به عنوان مجموعه تصاویر ($X$) تلقی می‌کنیم. }
این روش نیز $\pi$ را خطی و دسته‌بند $\phi$ را نزدیک‌ترین همسایه در نظر می‌گیرد. تابع هزینه مورد استفاده از این روش یک تابع هزینه‌ی رتبه‌بند است به این معنی که مانند  \cite{ akata13} به ازای  برچسب‌هایی که امتیاز بیشتری نسبت به برچسب صحیح کسب کرده‌اند، جریمه در نظر می‌گیرد:
\begin{equation}
 L((x_n, y_n);W) = \sum_{y\neq y_n} \max(0, \text{magrin} - x_nWc_{y_n} + x_nWc_y) 
\end{equation}

\subsubsection{سایر روش‌ها}\label{other}
یک راه‌حل مبتنی بر جنگل‌های تصادفی \LTRfootnote{Random Forest} در \cite{ jayaraman14} ارائه می‌شود. این روش در مرحله تشخیص ویژگی، برای هر ویژگی یک \lr{ SVM}  به طور مستقل یاد می‌گیرد. قسمت اصلی روش پیش‌نهادی در طراحی دسته‌بند $\phi$ است. این دسته‌بند با جنگل‌های تصادفی ساخته می‌شود اما از آن‌جایی که ویژگی‌های پیش‌بینی شده برای تصاویر احتمالا با بردار ویژگی توصیف کننده‌ی کلاس تفاوت‌هایی دارد، اجازه پیگیری همزمان چند مسیر در جنگل تصادفی داده می‌شود تا این عدم قطعیت در نظر گرفته شود. 
