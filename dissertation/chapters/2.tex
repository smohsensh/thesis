%------chapter 2: literature review
\chapter{روش‌های پیشین}
در این فصل ابتدا یک چارچوب کلی برای روش‌های مورد استفاده در یادگیری بدون برد توصیف می‌شود. سپس روش‌های موجود طبق این چارچوب دسته‌بندی شده و مرور خواهند شد. پیش از تعریف و بیان رسمی مسئثه یادیگری بدون برد، استفاده از اشتراک و تمایز برخی ویژگی‌ها میان دسته‌های مختلف در بینایی ماشین مورد بررسی قرار گرفته است
\cite{BakkerH03, TsochantaridisJHA05, ulman2005}
اما این روش‌ها به شناسایی دسته‌های کاملا جدید از روی این ویژگی‌ها توجه نشان نداده‌اند.
مسئله‌ی یادگیری تک‌ضرب\LTRfootnote{One-shot Learning}
هم یک مسئله نزدیک به یادگیری بدون برد است که پیش‌تر مورد بررسی بوده است
\cite{miller12}.
در حقیقت می‌توان یادگیری تک‌ضرب را حالت خاصی از یادگیری بدون برد در نظر گرفت که در آن توصیف دسته‌های دیده نشده به صورت یک نمونه از آن دسته ارائه شده است
\cite{bengio08}.

 پدیده شروع سرد\LTRfootnote{cold start}
 در سامانه‌های توصیه‌گر\LTRfootnote{Recommender Systems}
 را نیز می‌توان از حالت‌های خاص یادگیری بدون برد در نظر گرفت که در آن برای یک کاربر یا مورد جدید پیشنهاد صورت می‌گیرد.


بیان مسئله  یادگیری بدون برد به طور رسمی برای اولین بار در
\cite{bengio08}
صورت گرفت. در آن‌جا دو رویکرد کلی برای حل مسئله یادگیری بدون برد بیان می‌شود. یک روش که رویکرد فضای ورودی\LTRfootnote{input space view}
نامیده می‌شود، سعی در مدل کردن نگاشتی با دو ورودی دارد. یکی نمونه‌ها و دیگری توصیف دسته‌ها. این نگاشت برای نمونه‌ها و توصیف‌های مربوط به یک دسته امتیاز بالا و برای نمونه‌ها و توصیفاتی که متعلق به دسته‌ی یکسانی نیستند مقادیر کوچکی تولید می‌کند. با تخمین زدن چنین نگاشتی روی داده‌های آموزش، دسته‌بندی نمونه‌های آزمون در دسته‌هایی که تا کنون نمونه‌ای نداشته‌اند ممکن خواهد شد. به این صورت که هر نمونه با توصیف دسته‌های مختلف به این تابع داده شده و متعلق به دسته‌ای که امتیاز بیشتری بگیرد، پیش‌بینی خواهد شد.
در روش دیگر که رویکرد فضای مدل\LTRfootnote{model space view}
نام دارد، مدل مربوط به هر دسته (برای مثال پارامترهای دسته‌بند مربوط به آن)، به عنوان تابعی از توصیف آن دسته در نظر گرفته می‌شود.

ما در این فصل از دسته‌بندی دیگری برای مرور روش‌های پیشین استفاده می‌کنیم. برای این کار ابتدا معرفی یک چارچوب کلی برای انجام یادگیری بدون برد لازم است. دو رویکرد فوق نیز در این چارچوب قابل بیان هستند، این موضوع در بخش \ref{} که مثال‌هایی از این رویکردها مرور می‌شود، روشن‌تر خواهد شد.
 % چارچوبی که در ادامه می‌آید بر این اساس استوار است که تصاویر و توصیفات آن‌ها به یک فضای مشترک نگاشته می‌شوند. اگر بخواهیم دو دسته‌ی بالا در را در با این بیان توصیف کنیم، در رویکرد فضای ورودی، فضای مشترک فضایی است که نگاشت شباهت سنجی، ضرب داخلی آن فضاست و در رویکرد فضای مدل، فضای مشترک فضای دسته‌بندها خواهد بود.

 می‌توان گفت که هر روش برای یادگیری بدون برد از سه قسمت تشکیل شده است که ممکن است به صورت مستقل یا همزمان انجام شوند؛ این سه قسمت عبارتند از:
\begin{enumerate}
  \item یادگرفتن نگاشتی از فضای تصاویر به فضای مشترک
  که آن را با $\psi$ نشان می‌دهیم.
  \item نگاشت توصیف‌ها به فضای مشترک
  که آن را با $\phi$ نشان می‌دهیم.
  \item اختصاص برچسب به تصاویر
\end{enumerate}

\section{نماد‌گذاری}\label{notaion}
برای این که توصیف دقیق روش‌های پیشین ممکن باشد، در ابتدای یک نمادگذاری برای مسئله ارائه می‌دهیم و از آن برای بیان مرور روش‌های پیشین و بیان روش پیشنهادی در فصل آینده استفاده خواهیم کرد.

 تصاویر را با
 $x \in \mathbb{R}^d$
 نشان می‌دهیم که $d$ ابعاد داده را نشان می‌دهد. توصیف‌ها را با
 $ c \in \mathbb{R}^a$
 نمایش می‌دهیم که  $a$ ابعاد توصیف‌هاست. مجموعه دسته‌های دیده‌شده را با  $ \mathcal{S}$ و دسته‌های دیده‌نشده را با $ \mathcal{U}$ و مجموعه کل برچسب‌ها را با $ \mathcal{Y}$
 نشان می‌دهیم که
 $ \mathcal{Y} =  \mathcal{U} \cup \mathcal{S} $.
 تعداد دسته‌های آموزش را با $n_s$ و تعداد دسته‌های آزمون را با $n_u$ نشان می‌دهیم.
هم‌چنین   $c^y$ که در آن    $ y \in \mathcal{U} \cup \mathcal{S} $ بردار توصیف دسته $y$ را نشان می‌دهد.

    فرض می‌کنیم در زمان آموزش $ \{ (x^i, y^i) \}_{i=1}^{N_s} $ شامل $N_s$ تصویر از دسته‌های دیده شده به همراه برچسب  موجود است.
     $X_s \in \mathbb{R}^{N_s \times d}$
  مجموعه تصاویر و $Y_s$ برچسب‌های داده‌های آموزش با نمایش یکی یک
  \LTRfootnote{One-Hot Encoding}
   است. هم‌چنین توصیف‌های هر کدام از دسته‌های آموزش،
  $C_s \in \mathbb{R}^{s \times a}$
 نیز موجود است. $X_u$ و $C_u$ بطور مشابه برای دسته‌های آزمون تعریف می‌شوند.  $(X)_i$ سطر $i$م از ماتریس $X$ و $x_i$ درایه‌ی $i$م از بردار $x$ را نشان می‌دهد. ضرب داخلی با نماد  $\langle ., . \rangle $ نشان داده شده است.

در ادامه به بررسی روش‌های ارائه شده برای مسئله یادگیری بدون برد با استفاده از چارچوب ارائه شده خواهیم پرداخت.
\section{پیش‌بینی ویژگی  }
این دسته از روش‌ها عموما به حالتی از مسئله یادگیری بدون برد تعلق دارند که توصیف دسته‌ها از نوع بردار ویژگی باشد. در این حالت فضای مشترک همان فضای ویژگی‌ها در نظر گرفته می‌شود. به عبارت دیگر نگاشت $\psi$ نگاشت همانی فرض شده و یادگرفته نخواهد شد. روش‌های اولیه ارائه شده برای یادگیری بدون برد از نوع پیش‌بینی ویژگی\LTRfootnote{Attribute Prediction}
بوده‌اند و پس از آن‌ هم قسمت قابل توجهی از روش‌ها در این دسته جای می‌گیرند که در ادامه آن‌ها را به تفصیل مرور می‌کنیم.

\subsection{پیش‌بینی ویژگی مستقیم و غیر مستقیم}
در
\cite{lampert09}
با فرض این که ویژگی‌ها به صورت مستقل از یکدیگر قابل پیش‌بینی هستند دو رویکرد برای این کار ارائه می‌کند. پیش‌بینی ویژگی مستقیم\LTRfootnote{Direct Attribute Prediction}
و پیش‌بینی ویژگی غیر مستقیم\LTRfootnote{Indirect Attribute Prediction}.
 مدل گرافی مورد استفاده در این دو رویکرد در تصویر \ref{fig:dap} آمده است. در پیش‌بینی ویژگی مستقیم برچسب‌ها به شرط دانستن ویژگی‌های درون تصویر، از تصویر مستقل هستند. در این روش برای هر یک ویژگی‌ها یک دسته‌بند یاد گرفته می‌شود. با توجه به این که ویژگی‌ها برای تصاویر آزمون معین هستند این کار با استفاده از یک دسته‌بند احتمالی برای هر ویژگی قابل انجام است. در نهایت احتمال تعلق هر یک از برچسب‌های
$ u \in \mathcal{U} $
با استفاده از رابطه زیر بدست خواهد آمد.
\begin{equation} \label{eq:dap0}
  P(z_u | x ) = \sum_{c\in \{0,1\}^a} P(u | c) p(c|x)
\end{equation}
از با توجه به فرض استقلال ویژگی داریم
$P(c|x) = \prod_{n=1}^a P(c_m |x)$.
برای محاسبه جمله $P(z_u | a)$ از قانون بیز استفاده می‌کنیم:
\[
P(u | c) = \frac{P(u)P(c|u)}{P(a^{u})}  = \frac {P(u) \mathds{1}(c= c^{u})} {P(c^{u})}
\]
با جایگذاری در رابطه \eqref{eq:dap0} خواهیم داشت:
\begin{equation}
  P(u | x ) = \frac{P(u)}{P(c^{u})} \prod_{n=1}^a P(a^{u}_n|x)
\end{equation}
در نهایت برچسبی که احتمال فوق را بیشینه کند، پیش‌بینی مربوط به تصویر $x$ خواهد بود.

در روش پیش‌بینی ویژگی غیر مستقیم، IAP
 تخمین  $P(c_i|x) $ تغییر داده می‌شود؛ به این صورت که ابتدا یک دسته‌بند چند دسته‌ای یعنی $P(y_k |x)$ روی داده‌ها یاد گرفته می‌شود و سپس رابطه ویژگی‌ها و برچسب‌ها به صورت قطعی مدل می‌شود:
\begin{equation}
P(c_i | x) = \sum_{k=1}^{n_u} P(y_k | x) \mathbb{I}(c_i = c^{y_k}_i)
\end{equation}
در نهایت در هر دو روش برچسب نهایی با تخمین MAP\LTRfootnote{Maximum a Posteriori}
از رابطه زیر تعیین می‌شود:
\begin{equation}
\hat{y} = \argmax_{u \in \mathcal{U}} P(u|x) =  \argmax_{u \in \mathcal{U}} \prod_{i=1}^a \frac{P(c_i^u | x)}{P(c_i^u)}
\end{equation}
روش ارائه شده در
\cite{suzuki14}
مشابه همین روش است با این تفاوت که احتمال مشاهده هر کدام ویژگی‌ها را هم در محاسبه دخیل می‌کند تا با وزن‌های متفاوت با توجه به اهمیتشان در دسته‌بندی نقش داشته باشند. ضعف بزرگ این روش‌ها فرض مستقل بودن ویژگی‌ها از یکدیگر است؛ چرا که این فرض در مسائل واقعی معمولا بر قرار نیست. برای مثال زمانی که ویژگی آبزی بودن برای یک موجود در نظر گرفته می‌شود احتمال ویژگی پرواز کردن برای آن بسیار کاهش می‌یابد.
\subsection{مدل‌سازی احتمالی روابط بین ویژگی‌ها}
مدل‌های گرافی برای در نظر گرفتن وابستگی‌های میان ویژگی‌ها به کار گرفته شده‌اند. نویسندگان \cite{topicmodel} برای در نظر گرفتن ارتباط بین ویژگی‌ها و ارتباط ویژگی‌ها با برچسب نهایی روش‌های مدل‌سازی موضوع \LTRfootnote{  Topic Modeling} را از حوزه یادگیری در متن اقتباس می‌کنند. همچنین  نویسندگان \cite{unified13} برای این کار یک چارچوب بر اساس مدل‌های گرافی احتمال معرفی می‌کنند. در این چارچوب یک شبکه بیزی\LTRfootnote{  Baysian Network}  برای مدل کردن این روابط در نظر گرفته می‌شود و ساختار آن که نشان‌دهنده وابستگی یا استقلال ویژگی‌ها با هم یا با برچسب است، با کمک روش‌های یادگیری ساختار\LTRfootnote{Structure Learning}
شناخته می‌شود.

\section{نگاشت به فضای توصیف‌ها}
در برخی موارد توصیف‌های داده شده از جنسی غیر از ویژگی هستند ولی فضای مشترک همان فضای توصیف‌ها در نظر گرفته می‌شود و سعی می‌شود تصاویر به این فضا نگاشته شوند.
%------------------------------------------ConSE
روش ConSE\LTRfootnote{Convec combination of Semantic Embeddings}
 \cite{convec} 
از چنین نگاشتی استفاده می‌کند.  ابتدا یک شبکه عصبی کانولوشنال برای دسته‌بندی نمونه‌های دسته‌های دیده‌شده آموزش داده می‌شود. این یادگیری یک مسئله دسته‌بندی عادی است و شبکه‌ها در اکثر موارد از قبل به صورت پیش‌آموزش دیده شده وجود دارند. تابع فعال‌سازی\LTRfootnote{Activation Function} 
  لایه‌ی آخر این شبکه  به این صورت تعریف می‌شود:
 \begin{equation}
 \label{softmax}
 softmax(z)_j = \frac{e^{z_j}}{\sum_k e^{z_k}}, \quad j = 1, \ldots, n_s.
 \end{equation} 
 تابع بالا به ازای هر $j$، امتیاز تعلق نمونه به دسته‌ی $j$م را نشان می‌دهد. در هنگامی که با مسئله دسته‌بندی عادی روبرو هستیم، روی $j$ بیشینه گرفته می‌شود و دسته‌ای که بیشترین امتیاز را گرفته به عنوان پیش‌بینی خروجی داده می‌شود. در روش ConSE برای مسئله یادگیری بدون برد، هنگامی که یک نمونه از دسته‌های آزمون را به شبکه می‌دهیم، خروجی بدست آمده از رابطه \eqref{sotmax} می‌تواند به عنوان میزان شباهت آن نمونه به هر یک دسته‌های آموزش در نظر گرفته شود. 
  فرض کنید که برای هر نمونه
 $\hat{y}(x,n)$،
 $n$مین 
 عنصر بزرگ $softmax(x)$ را نشان دهد، یعنی $n$مین برچسب محتمل برای $x$ از میان دسته‌های آموزش. حالا برای پیش‌بینی برچسب $x$ از میان دسته‌های آموزش از این رابطه استفاده می‌کنیم:
 \begin{equation}
 \label{eq:conse}
 \phi(x) = \frac{1}{Z} \sum_{n=1}^T P(\hat{y}(x,n) | x) \cdot c_{\hat{y}(x,n)},
 \end{equation}
 که $T$ یک فراپارامتر مدل
 $Z = \sum_{n=1}^T P(\hat{y}(x,n) | x) $
 ضریب نرمال‌سازی است. در این حالت نمونه‌ی $x$ با تابع $\phi(\cdot)$ به فضای توصیف‌ها نگاشته شده است. به عبارت دقیق‌تر به صورت جمع وزن‌دار توصیف $T$ دسته‌ی شبیه‌تر نمایش داده شده است که وزن‌های این جمع میزان شباهت هستند. 
 % COSTA -----------------------------------------Extendtable
 روش \lr{COSTA}\LTRfootnote{Co-Occurance Statistics}
 \cite{costa}
 نیز از رویکرد مشابهی استفاده می‌کند. در این روش همانند رابطه \eqref{eq:conse}، پارامترهای دسته‌بند برای دسته‌های دیده نشده به صورت جمع وزن‌دار پارامترهای دسته‌بندهای دسته‌های دیده شده بیان می‌گردد. در این پژوهش برای بدست آوردن وزن‌های مربوط به شباهت میان دسته‌ها توابع مختلفی از تعداد رخ‌داد همزمان برچسب‌ها پیشنهاد شده است.




%----------------------------Bilinear maps 
\section{نگاشت‌های دو خطی}
حالت دیگری از چارچوب کلی معرفی شده در ابتدای فصل این است که نگاشت به فضای مشترک یک نگاشت دوخطی باشد. یعنی به این صورت که $W$ نگاشتی خطی است که $x^TW$ تصویر $x$ را به فضای توصیف‌ها نگاشته و $Wc$ توصیف $c$ را به فضای تصاویر می‌نگارد.در نهایت تابع مطابقت میان یک توصیف و تصویر به صورت زیر تعریف می‌شود:
\begin{equation}\label{bilinear}
F(x,c) = \phi(x)^TW \theta(y)
\end{equation}
 در این حالت، این که فضای مشترک در حقیقت کدام یک از فضاهای تصاویر یا توصیفات هستند، جواب روشنی ندارد. نقطه‌ی قوت این روش‌ها در امکان پیچیده‌تر کردن تابع هزینه است. چرا که در حالتی که نگاشت خطی است مسائل بهینه‌سازی پیچیده‌تری نسبت به حالت غیر خطی قابل حل خواهند بود.

 \subsection{یادگیری با توابع رتبه‌بند}
  یک انتخاب متداول برای تابع هزینه، توابع رتبه‌بند\LTRfootnote{ranking function}
هستند. با توجه به این که عموما بعد از یادگیری این نگاشت، دسته‌ای که نزدیک‌ترین توصیف را (با معیاری مثل فاصله یا ضرب داخلی) دارد، به عنوان پیش‌بینی تولید می‌شود،
 چنین تابع هزینه‌ای یک انتخاب طبیعی است. چرا که مسئله‌ی نزدیکترین همسایه در اصل یک مسئله رتبه‌بندی
 است و استفاده از یک تابع هزینه‌ی رتبه‌بند برای یادیگری نگاشت بهتر از مجموع مربعات است که تنها فاصله نقاط از برچسب خودشان را در نظر می‌گیرد \cite{devise}.

در
\cite{akata2013}
 تابع هزینه رتبه‌بند WSABIE
\cite{wsabie}
که برای حاشیه‌نویسی تصاویر پیشنهاد شده، به مسئله یادگیری بدون برد انطباق می‌دهد.
تابع هزینه WSABIE به این صورت تعریف شده است:

\begin{align}
L(x_s, Y_s ; W, \theta) = \frac{1}{N_s} \sum_{n=1}^{N_s} \lambda_{r_\Delta (x_n, y_n)} \sum_{y \in \mathcal{Y}} \max (0, \mathit{l}(x_n, y_n, y) ) \\
\mathit{l}(x_n,y_n,y) = \mathds{1}(y \neq y_n) + \phi(x_n)^TW \theta(y) - \phi(x_n)^TW\theta(y_n) \label{l_loss}
\end{align}

که در آن
$ r_\Delta (x_n, y_n) =  \sum_{y \in \mathcal{Y}} \mathbb{I}(\mathit{l}(x_n, y_n, y)  > 0) $
 و $\lambda_k$ یک تابع نزولی از $k$ است. این تابع، پیش‌بینی اشتباه ویژگی‌ها را  این گونه جریمه می‌کند که به ازای برچسب نادرستی که رتبه بالاتری از برچسب صحیح در دسته‌بندی دریافت کرده، جریمه‌ای متناسب با امتیاز برچسب ناصحیح در نظر گرفته می‌شود.ضریب نزولی $\lambda_k$ میزان جریمه را برای برچسب‌های غلط در رتبه‌های بالا، بیشتر در نظر می‌گیرد. در انطباق برای یادگیری بدون برد، بهینه‌سازی تنها روی نگاشت $W$ انجام شده و  تابع $\theta$ دانسته فرض می‌شود:
$\theta(y) = c_y$.


ایده‌ی بالا در \cite{Akata2015} ادامه داده شده و نگاشت شباهت ساخت‌یافته
\lr{SJE}\LTRfootnote{Structured Joint Embedding}
نامیده شده است.
، در این حالت تابع مطابقت بین توصیف‌ها و تصاویر از رابطه  \eqref{bilinear} تعریف می‌شود. تابع هزینه ساده‌تر از حالت قبل به صورت
\begin{equation} \label{sje_loss}
\frac{1}{N_s} \sum_{n=1}^{N_s} \max_{y \in \mathcal{Y}}(0, l(x_n, y_n, y))
\end{equation}
در نظر گرفته شده که $l$ همانند رابطه \eqref{l_loss} است. هم‌چنین برای استفاده از چند توصیف به صورت هم‌زمان، تعریف تابع مطابقت به صورت زیر تعمیم داده می‌شود:
\begin{align}
F(x,y;\{W\}_{1\ldots K}) &= \sum_k \alpha_k \theta(x)^T W_k \phi_k(y)  \\
s.t. & \sum_k \alpha_k = 1 \nonumber
\end{align}
که $\phi_k(y)$ توصیف‌های مختلف از دسته‌ی $y$ را نشان می‌دهد و $W_1, \ldots W_K$ نگاشت‌های میان هر یک از این توصیف‌ها و فضای تصاویر را. وزن‌های $\alpha_k$ که میزان اهمیت یا اطمینان  هر یک از توصیف‌ها را نشان می‌دهد، با اعتبارسنجی تعیین می‌شوند. روش \lr{SJE} با انواع اطلاعات جانبی سازگار است. اطلاعات جانبی که بر روی آن‌ها تست انجام شده است شامل بردار ویژگی‌های دودویی یا پیوسته تعیین شده توسط انسان و نمایش برداری متون دائره‌المعارفی با روش‌های \lr{word2vec} \cite{word2vec} و GloVe
\cite{pennington2014glove}
است. هم‌چنین نویسندگان این پژوهش یک نسخه با نظارت از \lr{word2vec} ارائه می‌دهند که در جریان آموزش آن از موضوع هر متن هم استفاده می‌شود.

 روش \lr{SJE} در \cite{Xian2016} برای برخی نگاشت‌های غیرخطی نیز تعمیم داده شده است. در این روش  که
 \lr{LatEm}\LTRfootnote{Latent Embedding Model}
 نام دارد تابع هزینه مانند حالت قبل (رابطه \eqref{sje_loss}) تعریف شده است با این تفاوت که تابع مطابقت میان توصیف و تصویر بجای رابطه دوخطی \eqref{bilinear} از این رابطه تبعیت می‌کند:
 \begin{equation} \label{latem}
 F(x,y) = \max_{1\leq i \leq L} \phi(x)^TW \theta(y)
 \end{equation}
در این حالت تابع مطابقت به صورت ترکیب نگاشت‌های دوخطی $W_1, \ldots W_M$ بیان شده است و یک تابع غیر خطی ولی تکه‌تکه خطی برای تصمیم‌گیری مورد استفاده قرار می‌گیرد.


در
\cite{devise}
نیز که برای اولین بار توصیف تنها نام برچسب دسته‌ها در نظر گرفته شده، از نگاشت دو خطی استفاده شده است. در این روش نام برچسب‌ها با استفاده از مدل نهان‌سازی کلمات \lr{word2vec} کلمات به بردارهایی نگاشته می‌شوند. ابعاد فضای نهان‌سازی کلمات یک فراپارامتر است که در این مقاله با اعتبار سنجی تعیین شده است. استخراج ویژگی از  تصاویر  با استفاده از شبکه عصبی کانولوشنال
\cite{alexnet}
که روی دسته‌های دیده شده آموزش داده شده، انجام می‌شود. در نهایت یک تابع بیشترین حاشیه\LTRfootnote{Max margin}
برای یادگیری نگاشت دو خطی پیشنهاد می‌شود.
\begin{equation}
 L((x_n, y_n);W) = \sum_{y\neq y_n} \max(0, \xi  - x_nWc_{y_n} + x_nWc_y)
\end{equation}
که در آن $\xi$ حاشیه دسته‌بندی است. دسته‌بندی نمونه‌های جدید با نگاشتن $x$ به فضای برچسب‌ها و استفاده از دسته‌بند نزدیکترین همسایه صورت می‌گیرد.

\subsection{روش‌های مبتنی بر خطای مجموع مربعات} \label{mse_loss_methods}

%-------------------------------------------- EZSL ----------------------------------------------------------------------------------
یک نحوه‌ی استفاده دیگر از نگاشت‌های دو خطی، دسته‌بندی مستقیم با این نگاشت است.
\begin{equation}
\minimize_{W \in \mathbb{R}^{d \times a}} \normf{X_s^T WC_s - Y} + \Omega(W) \label{eq:emb}
\end{equation}
که در آن $\Omega$ یک جمله منظم‌سازی است.
در این حالت اگر تبدیل را از فضای تصاویر به فضای ویژگی‌ها نگاه کنیم، نگاشت $W$ باید تصاویر را به زیرفضایی عمود به تمامی بردار ویژگی‌های مربوط به برچسب‌های نادرست بنگارد.
عملکرد خوب این روش، با وجود استفاده از تابع هزینه ساده مجموع مربعات خطا که در یادگیری ماشین تابع هزینه‌ی مناسبی برای دسته‌بندی به شمار نمی‌آید، به جمله منظم سازی آن نسبت داده می‌شود. جمله منظم‌سازی $\Omega$ به این صورت تعریف می‌شود:
\begin{equation} \label{eq:emb_reg}
\Omega(W) = \lambda \normf{WC_s} + \gamma \normf{X_s^T W}  + \lambda \gamma \normf{W}
\end{equation}
این جمله منظم‌سازی با دیدگاه نگاشت دوخطی طبیعی است. چرا که ماتریس $WC_S$ را می‌توان یک دسته‌بند خطی روی فضای تصاویر در نظر گرفت و از طرفی ماتریس $X_s^T W$ یک دسته‌بند روی بردارهای ویژگی است در نتیجه طبیعی است که پارامترهای این دو دسته‌بند با نرم فروبنیوس آن‌ها کنترل شود تا از بیش‌‌برازش\LTRfootnote{overfitting}
 جلوگیری شود.
استفاده از توابع نرم دوم برای خطا و منظم‌سازی در این روش باعث شده است که مسئله بهینه‌سازی جواب به صورت فرم بسته داشته باشد و زمان اجرا نسبت به سایر روش‌ها بسیار کمتر باشد.

%----------------------------------------------------------------------------LESS IS MORE
این روش در
\cite{lessismore}
برای توصیفات متنی توسعه داده شده است. با توجه به ابعاد بالای داده‌های متنی و همچنین نویز زیادی که در آن‌ها در مقایسه با بردارهای ویژگی وجود دارد، ماتریس تبدیل $W$ به دو ماتریس تجزیه می‌شود:
\begin{equation}
W = V_x^T V_c
\end{equation}
با این تجزیه از افزایش شدید تعداد پارامترها در اثر افزایش بعد بردار توصیف‌ها جلوگیری می‌شود. (دقت کنید که بعد $C$ برابر $d\times a$ است) علاوه بر این $V_c$ می‌تواند برای استخراج ویژگی‌های مفید و حذف نویز از  $C$ به  کار گرفته شود و $V_x$ مانند $W$ در حالت اصلی عمل کند یعنی پارامترهای یک دسته‌بند را از روی توصیف‌ها تولید کند. در نهایت تابع هزینه برای این روش به صورت زیر تعریف می‌شود:
\begin{equation}
\min_{V_x, V_c} \normf{X_s^T + V_x^T V_c C} + \lambda_1 \normf{ V_x^T V_c C} +
\lambda_2 \norm{V_c^T}_{2,1}
\end{equation}
که
$\norm{M^T}_{2,1} = \sum_i \norm{M_{(i)}}_2 $
و این نوع منظم‌سازی، ستون‌های ماتریس $V_c$ را به سمت تنک بودن سوق خواهد داد. در واقع اگر $\lambda_2$ بزرگ انتخاب شود، $V_c$ نقش یک ماتریس انتخاب ویژگی\LTRfootnote{feature selection}
را خواهد داشت. جمله‌های منظم سازی دیگر در
\eqref{eq:emb_reg}
به دلیل تاثیر اندکشان در آزمایشات عملی حذف شده‌اند.


\section{نگاشت به فضای تصاویر}\label{to_images}
در برخی از روش‌ها فضای مشترک فضای ویژگی‌های تصویر است و نگاشتی از توصیف‌ها به این فضا یاد گرفته می‌شود و مطابقت تصویر و توصیف در این فضا قابل سنجیدن می‌شود. از آن‌جا که در این روش‌‌ها، استخراج ویژگی از تصاویر با توابع از پیش معین صورت می‌گیرد این روش‌ها را با عنوان نگاشت به فضای تصاویر بررسی می‌کنیم.


 یک تعمیم  از \lr{SJE} در \cite{Reed2016} ارائه شده است. در این روش که برای تصاویر مجموعه متون بزرگتری نسبت به دادگان قبلی جمع‌آوری و استفاده شده است.
  این ازدیاد در داده‌ها امکان آموزش مدل‌های پیچیده‌تر و پیشرفته‌تر را برای یادگیری نگاشت از فضای تصاویر فراهم می‌کند و فاصله میان عمل‌کرد یادگیری بدون برد هنگام استفاده از
  توصیف‌های متنی و توصیف‌های به صورت بردار ویژگی را کمتر کرده است.
  در این حالت فرض می‌شود که داده‌های آموزش به صورت
   $\{(v_{n},t_{n},y_{n}), n = 1, ..., N\}$
   است که متشکل است از
    $v \in \mathcal{V}$
    که ویژگی‌های تصویری هستند،
     $t \in \mathcal{T}$ توصیفات متنی و $y \in \mathcal{Y}$ برچسب‌ها.
      دقت کنید که در توصیف این روش بر خلاف سایر روش‌ها از نمادگذاری معرفی شده در این بخش استفاده نکرده‌ایم.
      نمادهای استفاده شده منطبق بر نمادهای مقاله اصلی می‌باشند. دلیل این موضوع این است که ویژگی‌های تصویری $v_n$ با با تصاویر  $x_n$ متفاوت است. در نمادگذاری ما هر $x$ در رابطه یک‌به‌یک با یک تصویر آموزش یا آزمون است در حالی‌که در مجموعه آموزش معرفی‌شده در بالا هر تصویر با چند مجوعه ویژگی بصری $v$ در مجموعه آموزش حضور دارد و هر کدام از این ويژگی‌های بصری $v_n$، یک متن مربوط به خود دارد که با $t_n$ نشان داده ‌شده است. هم‌چنین فرض کنید که  $\mathcal{T}(y)$ و $\mathcal{V}(y)$ به ترتیب مجموعه تمامی متون و ویژگی‌های بصری مربوط به کلاس $y$ را نشان می‌دهند.
  در این حالت هدف یادگیری تابع مطابقت $F : \mathcal{V} \times \mathcal{T} \rightarrow \mathbb{R}$ میان تصاویر و توصیف‌هاست. که به صورت
  \begin{equation}
  \label{eq:akata16comp}
F(v, t) = \theta(v)^T\phi(t)
  \end{equation}
در نظر گرفته شده است. با داشتن چنین تابعی، مشابه سایر روش‌ها پیش‌بنی برچسب برای تصاویر یا حتی متون جدید با معادلات زیر صورت می‌پذیرد:
\begin{align}
\label{eq:akata16class}
f_v(v) = \underset{y \in \mathcal{Y}}\argmax ( \mathbb{ E}_{t \sim \mathcal{T}(y)}[F(v, t)])\\
f_t(t) = \underset{y \in \mathcal{Y}}\argmax (\mathbb{ E}_{v \sim \mathcal{V}(y)}[F(v, t)]).
\end{align}
یادگیری تابع $F$ با تابع هزینه‌ی زیر صورت می‌گیرد:
\begin{align}
\label{eq:objective_actual}
\dfrac{1}{N}\sum_{n=1}^{N} \ell_v(v_n, t_n, y_n) + \ell_t(v_n, t_n, y_n),
\end{align}
که توابع $ \ell_t$ و $\ell_v$ این گونه تعریف شده اند:
\begin{align*}
\ell_v(v_n, t_n, y_n) &=  \underset{y \in \mathcal{Y}}{\max}(0,\Delta(y_n, y) + \mathbb{E}_{t \sim \mathcal{T}(y)} [ F(v_n,t) - F(v_n,t_n) ]) \\
\ell_t(v_n, t_n, y_n) &= \underset{y \in \mathcal{Y}}{\max}(0,\Delta(y_n, y) + \mathbb{E}_{v \sim \mathcal{V}(y)} [ F(v,t_n) - F(v_n,t_n)])
\end{align*}
تفاوت این تابع هزینه با  رابطه \eqref{sje_loss} در اضافه شدن جمله‌ی دوم است. در  رابطه \eqref{sje_loss} این مسئله که هر تصویر طوری نگاشته شود که به توصیف درست نزدیک‌تر از بقیه توصیف‌ها باشد در نظر گرفته می‌شد، در رابطه بالا علاوه به این مسئله، نگاشت‌ها باید طوری باشد که هر توصیف باید به ويژگی بصری خود نزدیک‌تر باشد تا سایر ویژگی‌های بصری.
نگاشت $\theta$ مانند سایر روش‌ها یک شبکه عصبی عمیق کانولوشنال است که از قبل با داده‌های \lr{ImageNet} آموزش داده شدهاست. برای هر تصویر قسمت‌های بصری مختلف با بریدن قسمت‌های متفاوت از تصویر حاصل می‌شود. نگاشت $\phi$ برای متون با سه شبکه عصبی مختلق کانولوشنال، بازگردنده و کانولوشنال بازگردنده\lr{ (CNN-RNN) } مدل شده است. استفاده از این شبکه‌ها برای نگاشت متن در این روش نخستین بار در این روش رخ داده‌است. جمع‌آوری مجموعه دادگان متنی بزرگتر، آموزش چنین شبکه‌هایی را ممکن کرده است.

در  \cite{mohamed13} که برای نخستین بار توصیف‌ها از نوع متنی مورد بررسی قرار گرفته شده است، راه‌حل پیشنهادی یادگیری نگاشتی از این توصیفات به فضای تصاویر است. حاصل این نگاشت یک دسته‌بند خطی در فضای تصاویر در نظر گرفته می‌شود. اگر این نگاشت را طبق نمادگذاری معرفی شده با $\phi$ نشان دهیم دسته بندی با استفاده از رابطه زیر انجام خواهد شد:
\begin{equation} \label{eq:linear_classifier}
y^* = \argmax_y \phi(c^y)^T x
\end{equation}


برای یادگیری $\phi(c)$ از ترکیب دو تخمین‌گر استفاده می‌شود:
\begin{enumerate}
\item
رگرسیون احتمالی: توزیع $P_{reg}$ یادگرفته می‌شود که برای یک توصیف $c$ و نگاشت در فضای تصاویر $w$ احتمال $P_{reg}(w|c)$ را مدل می‌کند.
\item
تابع مطابقت: نگاشت دو خطی $D$ که تطابق میان دامنه تصاویر و توصیف‌ها مدل می‌کند به عبارت دیگر $c^TDx$ زمانی که $x$ به دسته‌ای که   $c$ توصیف می‌کند تعلق دارد بزرگتر از مقدار آستانه‌ای است و در غیر این صورت کوچک‌تر از آن. می‌توان مشاهده کرد که در این حالت با استفاده از رابطه
\eqref{eq:linear_classifier}،
 $c^TW$
یک  دسته‌بند خطی برای دسته‌ای که $c$ توصیف می‌کند، خواهد بود.
\end{enumerate}

پارامترهای $P_{reg}$ و $D$ با استفاده از نمونه‌های آموزش بدست می‌آیند.
در نهایت تابع پیشنهادی برای نگاشت $\phi$ برای دسته‌های آزمون به صورت زیر تعریف می‌شود:
\begin{align}
\label{eq:write_a}
\phi(c) &= \argmin_{w,\zeta_i} w^Tw - \alpha c^TDw -\beta \, ln(P_{reg}(w|c)) + \gamma \sum \zeta_i \\
s.t. \, &: -(w^tx_i) \geq \zeta_i, \quad \zeta_i \geq 0, \, i=1,\ldots N_s  \nonumber \\
& c^TDc \geq l \nonumber
\end{align}
که $\alpha, \beta, \gamma, l$ فراپارامترهای مدل هستند. جمله اول در این تابع هزینه، منظم‌سازی دسته‌بند خطی $w$ است. جمله دوم مشابهت $w$ با $c^TD$ را الزام می‌کند و جمله سوم احتمال بالا در رگرسیون را در نظر می‌گیرد. محدودیت $-(w^Tx_i) \geq \zeta_i$ بر اساس فرض عدم تعلق
نمونه‌های آزمون به کلاس‌های دیده‌شده تعریف شده است و اجبار می‌کند که تمامی نمونه‌های دیده‌شده باید در طرف منفی دسته‌بند خطی $w$ قرار گیرند.
نویسندگان این پژوهش، روش خود را با استفاده از تکنیک هسته
\LTRfootnote{kernel trick}
برای دسته‌بندهای غیرخطی نیز توسعه داده‌اند \cite{elhoseiny2015}.

\section{نگاشت به یک فضای میانی}
در برخی روش‌ها هر دوی نگاشت‌های $\phi$ و $\theta$، معرفی شده در ابتدای فصل با توجه به داده‌ها یاد گرفته می‌شوند و در نتیجه فضای مشترک مورد استفاده نه فضای تصاویر و نه فضای توصیف‌هاست؛ بلکه فضای ثالثی است. این فضای میانی در برخی از روش‌ها یک فضای با بعد کمتر است و تعبیر معنایی برای آن موجود نیست. در برخی روش‌های دیگر، فضای میانی را با بعد $n_s$ یعنی تعداد دسته‌های دیده شده در نظر گرفته‌اند و تعبیر معنایی برای آن ارائه شده است. این فضای میانی بر اساس توصیف دسته‌ها و نمونه‌های دیده نشده بر اساس شباهت آن‌ها با دسته‌های دیده شده استوار است.

%-------------predicting salakhudtinov
\begin{figure}[h] \label{fig:deep}
\begin{center}
\includegraphics[width=7cm]{images/ba.jpg}
\end{center}
\caption{
 شبکه مورد استفاده برای یادگیری توام نگاشت تصاویر و توصیف‌ها که یک شبکه عصبی عمیق با دو ورودی است. ورودی اول از نوع تصویر است و ابتدا با یک شبکه کانولوشنال سپس با چند لایه چگال به فضایی $k-$بعدی می‌رود. ورودی دوم که یک مقاله از ویکی‌پدیای انلگیسی است پس از تبدیل به نماش برداری به صورت \lr{tf-idf} با چندلایه با اتصالات چگال پردازش شده و به فضایی $k-$بعدی می‌رود. در نهایت امتیاز تعلق تصویر به دسته‌ی متن با ضرب داخلی این دو نگاشت تعیین می‌شود \cite{ba2015}.
}
\end{figure}

در  \cite{ba2015} از شبکه‌های عصبی عمیق برای یادگیری توام نگاشت‌های $\phi$ و $\theta$ استفاده شده است. نمای کلی شبکه مورد استفاده در این روش در تصویر
\ref{fig:deep}
نشان داده شده است. توصیف‌های متنی و ويژگی‌های بصری دو ورودی جداگانه به چنین شبکه‌ای هستند که ابتدا به صورت جداگانه با یک یا چند لایه‌ی با اتصالات کامل به یک فضای مشترک نگاشته شده و سپس بر اساس شباهت نمایش آن‌ها در این فضای میانی دسته‌بندی می‌شوند. تفاوت این روش با سایر روش‌هایی که مرور شد یادگیری توامان نگاشت‌های  $\phi$ و $\theta$ است که با استفاده از شبکه‌های عصبی ممکن شده است. معیار یادگیری این دو نگاشت تنها خطای دسته‌بندی نهایی است.
این روش را می‌توان به صورت ساخت دسته‌بند از روی توصیفات نیز تعبیر کرد؛ با این تفاوت که در این حالت یک تبدیل نیز روی فضای تصاویر اعمال شده و سپس دسته‌بند خطی یادگرفته شده از متون در این فضا به نگاشت تصاویر اعمال می‌شود. در این حالت دسته‌بند خطی $w^y$ یک تابع غیر خطی از توصیف کلاس $y$ است: $w^y = f(c^y)$ که $f$ شبکه عصبی مخصوص متن است (نیمه‌ی چپ تصویر \ref{fig:deep}.) استخراج ویژگی غیر خطی از تصاویر نیز با یک شبکه عصبی که تابع آن را $g$ می‌نامیم، انجام شده است(نیمه‌ی راست تصویر \ref{fig:deep}.) در نهایت دسته‌بندی با تابع زیر انجام می‌شود:
\begin{equation} \label{eq:ba_classifier}
y^* = \argmax_y{w^{yT} g(x)}.
\end{equation}
این روش فراتر از دسته‌بند خطی به حالت فوق نیز با معرفی دسته‌بند کانولوشنال توسعه پیدا می‌کند. در شبکه‌های عصبی کانولوشنال، اطلاعات مکانی در  لایه‌های با اتصال چگال از بین می‌رود. هم‌چنین تعداد وزن‌ها در این لایه‌ها بسیار بیشتر از لایه‌های کانولوشنال زیرین است. در نتیجه بنظر می‌رسد استفاده مستقیم از خروجی لایه‌ی کانولوشنال و اضافه کردن یک لایه کانولوشنال دیگر یادگیری فیلتر بر اساس متن می‌تواند راه‌حل مناسب‌تری از یادگیرفتن یک یا چند لایه‌ی چگال باشد.

فرض کنید $b$ خروجی یک لایه‌ی کانولوشنال با $M$ نقشه از ویژگی‌های تصویر باشد: $b \in \mathbb{R}^{M\times l \times h}$ که $h$ و $l$ ارتفاع و عرض نقشه ویژگی‌ها هستند. دسته‌بند روی $b$ به صورت یک لایه‌ی کانولشنال فورمول‌بندی می‌شود. ابتدا یک کاهش ابعاد غیر خطی روی هر یک از نقشه‌های ویژگی صورت می‌گیرد که آن را با $g'$ نشان می‌دهیم:
$g': \mathbb{R}^{M\times l\times h} \mapsto \mathbb{R}^{K'\times l\times h}$
که
$K' << M$.
در ادامه از نماد  $a'$ برای نقشه ویژگی کاهش بعد یافته استفاه می‌کنیم
$a' = g'(a)$.
از یک توصیف مثل $c^y$ یک  فیلتر کانولوشن $w^y = f'(c^y)$ ایجاد می‌شود که اگر اندازه فیلتر را با $m$ نشان دهیم: $w'_c \in \mathbb{R}^{K' \times m \times m}$. همانند حالت قبل، $f'$ با یک شبکه عصبی چند لایه مشخص می‌شود. در نهایت دسته‌بند کانولوشنال به صورت زیر تعریف می‌شود:
\begin{align}
\label{eq:conv}
\text{score}(x,y)=o\bigg(\sum_{i=1}^{K'}w^{y'}_{i}\  \check{*} \  a'_i\bigg),
\end{align}
 $\text{score}(x,y)$
  امتیاز تعلق $x$ به دسته‌ی $y$ است؛ $o(\cdot)$ یک تابع ادغام\LTRfootnote{pooling} به صورت $o:\mathbb{R}^{l\times h} \mapsto \mathbb{R}$  و $\check{*}$ نشان‌گر عمل کانولوشن است. در این حالت فیلترهای یادگرفته شده به علت این که به محل تصویر وابسته هستند می‌توانند با دقت بهتری تطابق توصیف‌های متنی و تصویر را نشان دهند.

  در نهایت در این پژوهش استفاده همزمان از دسته‌بندهای خطی و کانولوشنال پیشنهاد می‌شود که در با استفاده از آزمایشات عملی نشان داده شده عمل‌کرد بهتری خواهد داشت. برای استفاده همزمان از این دو دسته‌بند امتیاز تطابق از جمع این دو بدست می‌آید:
\begin{align}
\text{score}(x,y)=w^{yT}g(x) + o\bigg(\sum_{i=1}^{K'}w^{y'}_{i}\  \check{*} \  g'(a)_i\bigg).
\end{align}
در این حالت پارامترهای مربوط به $g, g', f , f'$ به صورت همزمان یادگرفته می‌شوند.
یادگیری در شبکه بر اساس خطای تنها خروجی که نشان می‌دهد آیا این متن و توصیف هم‌دسته هستند یا نه صورت می‌گیرد. در این پژوهش دو تابع هزینه برای خطا در نظر گرفته شده ۱) آنتروپی تقاطعی
\LTRfootnote{Cross Entropy}
۲) تابع هزینه لولا\LTRfootnote{hinge loss}. بررسی عمل‌کرد این دو نوع تابع هزینه نشان می‌دهد که بر اساس معیار ارزیابی نهایی هر کدام می‌توان عمل‌کرد بهتری نسبت به دیگری داشته باشد. اگر معیار ارزیابی دقت دسته‌بندی در $k$ انتخاب اول\LTRfootnote{top-k accuracy} باشد تابع هزینه لولا بهتر عمل می‌کند و اگر معیار مساحت زیر نمودار صحت و بازیابی\LTRfootnote{Precision Recall Area Under the Curve} باشد، آنتروپی متقاطع عمل‌کرد بهتری دارد.

 
 %-----------------------------------Desiging category level attributes ------------extendtable
 در \cite{Yu2013} روشی برای ساخت بردارهای ویژگی برای تصاویر، برای دسته‌بندی بهتر آن‌ها، در حالت عادی دسته‌بندی تصاویر، ارائه شده است. این روش برای هر دسته یک بردار ویژگی و برای هر یک از ويژگی‌ها یک دسته‌بند یاد می‌گیرد. 
  این روش برای یادگیری بدون برد هم تعمیم داده شده است. این روش با سایر روش‌ها در نوع توصیفی که برای دسته‌ها استفاده می‌کند کاملا متفاوت است. در این روش بردار ویژگی برای دسته‌ها جزو خروجی‌های روش است نه ورودی‌های آن. در این‌جا الگوریتم هیچ توصیفی از دسته‌های دیده شده دریافت نمی‌کند و دسته‌های دیده نشده بر اساس شباهتشان با دسته‌های دیده شده توصیف می‌شوند و در نهایت الگوریتم برای همه دسته‌ها بردار ویژگی تولید می‌کند. فرض کنید در کل $n$ دسته موجود باشد و و قصد داشته باشیم بردار ویژگی‌های $l$ بعدی تولید کنیم ($l$ یک فراپارامتر است). ماتریس این ويژگی‌ها را با 
  $ A \in \mathbb{R}^{n \times l}$
  نشان می‌دهیم. هدف در این جا بدست آوردن $A$ و هم‌چنین دسته‌بند
$f = [f_1 \ldots f_l]^T$
   برای ویژگی‌هاست. در نهایت یک نمونه با استفاده از رابطه زیر قابل دسته‌بندی خواهد بود:
 \begin{equation}
 \label{eq:desing1}
 y^* = \argmin_i \lVert A_{(i)} - f(x)^T \rVert
 \end{equation}
 نویسندگان این پژوهش عنوان می‌کنند که بردار ویژگی یادگرفته شده برای خوب بودن باید دو خاصیت را داشته باشد:
 \begin{itemize}
 \item 
 ایجاد تمایز: بردار ویژگی هر دسته باید با دسته دیگر، به اندازه کافی متفاوت باشد.به عبارت دیگر سطرهای ماتریس $A$ از هم فاصله داشته باشند.
 \item
 قابل یادگیری بودن: ویژگی‌ها باید با خطای کم از روی تصاویر قابل پیش‌بینی باشند. یک روش برای ایجاد چنین حالتی این است که ویژگی‌ها باید میان دسته‌های مشابه یکدیگر، شبیه باشد.
 \end{itemize}
اثبات می‌شود خطای دسته‌بندی کرانی بر اساس دو عامل بالا، یعنی حداقل فاصله سطرهای $A$ و حداکثر خطای دسته‌بند $f$ خواهد داشت. 
برای یادگیری $A$ طوری که دو خاصیت فوق را داشته باشد تابع هزینه 
\begin{equation}
\label{eq:design2}
\max_A \sum_{i,j} \norm{A_{(i)} - A_{(j)}}_2^2 - \lambda \sum_{i,j} S_{ij} \norm{A_{(i)} - A_{(j)}}_2^2
\end{equation}
پیشنهاد شده است.
$ S \in \mathbb{R}^{n \times n}$
 ماتریسی است که عناصر آن شباهت میان دسته‌ها را نشان می‌دهد. جمله اول، جمع فاصله سطرهای $A$ از هم است و  برای ایجاد خاصیت اول یعنی ایجاد تمایز در نظر گرفته شده است. جمله دوم تحمیل می‌کند که دسته‌های مشابه یکدیگر بایست ویژگی‌های بصری مشابه داشته باشند تا بتوان این ویژگی‌ها را از تصویر پیش‌بینی کرد. 
 در مسئله دسته‌بندی عادی، $S$ از روی داده‌های برچسب‌دار و  فاصله تصاویر هر دسته از دسته‌ی دیگر تعیین می‌شود. برای مسئله یادگیری بدون برد، مقادیر $S$ برای دسته‌های دیده نشده به عنوان ورودی دریافت می‌شود و با کمک $f$ که از داده‌های آموزش یادگرفته شده دسته‌بندی آن‌ها با رابطه 
 \eqref{eq:desing1}
  انجام می‌شود.


\subsection{نگاشت به فضای دسته‌های دیده شده}
با توجه به این که یادگیری تابع تعیین شباهت هر نمونه با دسته‌های آموزش تنها به نمونه‌های آموزش نیاز دارد می‌تواند به طور کامل در زمان آموزش انجام شود. بر این اساس اگر دسته‌های دیده نشده به خوبی بر اساس شباهتشان با دسته‌های دیده شده قابل توصیف باشند، می‌توان یک معیار مطابقت میان آن‌ها و نمونه‌های آزمون بدست آورد. (مثلا بر اساس ضرب داخلی یا فاصله اقدلیدسی در این فضا) در زمینه‌ی یادگیری بدون برد چند روش بر این اساس ارائه شده است. بعضی از این روش‌ها توصیف دسته‌های آزمون بر اساس دسته‌های آموزش را به عنوان ورودی دریافت می‌کنند و برخی دیگر توانایی بدست آوردن این نمایش را بر اساس توصیف‌های جانبی دارند. 


 


