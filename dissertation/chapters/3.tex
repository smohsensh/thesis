%------chapter 3: works
\chapter{روش پیشنهادی} \label{chap:proposed}
در این فصل به بیان روش‌های پیشنهادی در این پژوهش برای مسئله یادگیری صفرضرب می‌پردازیم. روش‌های مطرح شده در این فصل از دو رویکرد متفاوت برای حل مسئله یادگیری صفرضرب استفاده می‌کنند. یک رویکرد یافتن نگاشت از فضای تصاویر به فضای توصیف دسته‌ها است که این نگاشت با استفاده از شبکه‌های ژرف مدل شده است. رویکرد دوم با انجام یک خوشه‌بندی در فضای ویژگی‌های ژرف استخراج شده از تصاویر و با یادگرفتن نگاشتی از فضای توصیف دسته‌ها به فضای ویژگی‌های ژرف تصاویر همراه است.

در ابتدای این بخش به مسئله استخراج ویژگی از تصاویر با استفاده از شبکه‌های ژرف می‌پردازیم، فضای تشکیل شده از ویژگی‌های تصاویر هنگام استفاده از این شبکه‌ها، دارای خاصیت جدایی پذیری دسته‌های مختلف از هم و تشکیل خوشه‌هایی از نمونه‌های هر دسته است؛ فرض وجود چنین خاصیت‌هایی در فضای ویژگی‌های تصاویر، اساس روش‌های ارائه شده در این فصل است.
در بخش \ref{nn} یک شبکه‌ی عصبی چندوظیفه‌ای برای پیش‌بینی ویژگی از تصاویر معرفی می‌کنیم که با در نظر گرفتن نمونه‌های آزمون در زمان آموزش می‌تواند مشکل جابجایی دامنه را کاهش دهد. در بخش \ref{hist} یک شبکه عصبی برای نگاشت تصاویر به هیستوگرامی از میزان شباهت به دسته‌های دیده شده معرفی می‌کنیم و با استفاده از آن روش دیگری برای دسته‌بندی صفرضرب پیشنهاد می‌دهیم.
در بخش
\ref{compatibility_function}
 یک تابع مطابقت نوین برای مسئله دسته‌بندی صفرضرب معرفی می‌کنیم که استفاده از اطلاعات غیرنظارتی موجود در ساختار نمونه‌های دسته‌های دیده نشده را ممکن می‌سازد. این تابع مطابقت از یک خوشه‌بندی روی نمونه‌های آزمون بهره می‌برد که با توجه به استخراج ویژگی‌ها با استفاده از شبکه‌های عصبی ژرف و جداسازی مناسب در فضای این ویژگی‌ها، از دقت مناسبی برخوردار است. این تابع مطابقت به نمونه‌هایی که در یک خوشه قرار دارند برچسب یکسانی نسبت می‌دهد. با توجه به استفاده از خوشه‌بندی در این تابع مطابقت، یک روش خوشه‌بندی نیمه‌نظارتی که منطبق بر فرضیات مسئله یادگیری صفرضرب است ارائه می‌گردد و سپس یک روش دسته‌بندی با استفاده از تابع مطابقت و خوشه‌بندی ارائه شده و یادگیری نگاشتی خطی از توصیف دسته‌ها به فضای تصاویر، تدوین می‌گردد. هرچند که عملکرد این روش ارائه شده برتر از روش‌های پیشگام موجود است ولی محدودیت‌هایی نیز دارد که ناشی از جدا بودن مرحله خوشه‌بندی و نگاشت به فضای مشترک است؛ برای رفع این محدودیت‌ها روش دیگری معرفی می‌شود که خوشه‌بندی و یادگیری نگاشت در آن به صورت توام انجام می‌شود. این یادگیری توام باعث بهبود دقت دسته‌بندی نسبت به روش پیشنهادی قبلی می‌شود.

نمادگذاری مورد استفاده در این فصل سازگار با نمادگذاری معرفی شده در بخش ۲ است که در جدول \ref{tab:notation} برای مراجعه سریع خلاصه شده است.
\begin{center}
\begin{table}[ht]
\centering
\caption{معرفی نمادهای مورد استفاده}
\vspace{2mm}
\label{tab:notation}
\begin{tabular}{|c|r|}
\hline
 نماد &  شرح \\
\hline
  $\mathcal{S}(\mathcal{U})$ & \rl{مجموعه دسته‌های دیده‌شده (دیده‌نشده) }     \\\hline
  $n_s (n_u) $ & \rl{تعداد دسته‌های دیده‌شده (دیده‌نشده) }   \\\hline
  $N_s (N_u) $ & \rl{تعداد نمونه‌های آموزش (آزمون) }   \\\hline
  $X_s (X_u) $ & \rl{ماتریس نمونه‌های آموزش (آزمون) }   \\\hline
  $Y_s (Y_u) $ & \rl{برچسب‌های نمونه‌های آموزش (آزمون) }   \\\hline
  $C_s (C_u) $ & \rl{ماتریس توصیف‌های دسته‌های دیده‌شده (دیده‌نشده) }   \\\hline
  $\mathbf{x_i}  \in \mathbb{R}^d$ & \rl{ بردار ویژگی‌های تصویر $-i$م}   \\\hline
 $ \mathbf{c_y}  \in \mathbb{R}^a$ & \rl{بردار توصیف دسته‌ی $y$}   \\\hline
\hline
 $X_{(i)}$ & \rl{سطر $-i$م ماتریس $X$} \\ \hline
 $\normf{X}$ & \rl{نرم فروبنیوس ماتریس $X$} \\ \hline
 $diag(\mathbf{x})$ & \rl{یک ماتریس قطری که بردار $\mathbf{x}$ روی قطر اصلی آن قرار داده شده} \\ \hline
 $\mathbf{1}$ & \rl{یک بردار که تمام عناصر آن برابر یک است} \\ \hline
 $\mathbf{1}_k$ & \rl{یک بردار که درایه‌ی $-k$م آن یک و سایر عناصرش صفر است } \\ \hline
\end{tabular}
\end{table}
\end{center}
\section{استخراج ویژگی با شبکه‌های عصبی ژرف}\label{cnns}
 در سال‌های اخیر استفاده از شبکه‌های عصبی پیچشی ژرف کاراترین روش برای استخراج ویژگی از تصاویر بوده است \cite{Oquab2014}. این شیوه‌ی استخراج ویژگی که با استفاده از تعداد زیادی داده‌ی برچسب‌دار
\textit{یاد گرفته می‌شود،}
جایگزین روش‌های قبلی مانند SIFT و HOG شده است که در آن‌ها، نحوه‌ی استخراج ویژگی توسط یک خبره تعیین شده و همواره ثابت است.
 در این شبکه‌ها در هر لایه عموما از چندین \gls{filter} استفاده می‌شود. تعداد کم پارامترهای \gls{filter} و استقلال آن از اندازه تصویر ورودی، باعث شده تعداد پارامتر‌های موجود در یک لایه‌ی پیچشی بسیار کمتر از یک \gls{fully-connected-layer} باشد و در نتیجه امکان افزایش عمق شبکه بیشتر باشد.
\begin{figure}[!t]
\centering
\includegraphics[width=1.1\linewidth]{images/vgg}
\caption[ساختار شبکه استخراج ویژگی]{
ساختار شبکه vgg که در آن لایه‌های سفید مراحل ادغام که اینجا انتخاب بیشینه در پنجره‌های $2 \times 2$ است را نشان می‌دهند.
لایه‌های پیچشی با مکعب‌های آبی مشخص شده‌اند که عرض آن‌ها متناسب با تعداد کانال‌های موجود در آن لایه است \cite{el2016face}.
}
\label{fig:vgg}
\end{figure}
معماری مورد استفاده در روش‌های این فصل برای استخراج ویژگی، مبتنی بر معماری ۱۹ لایه شبکه \lr{vgg} \cite{vgg} است (شکل \ref{fig:vgg}). در این شبکه از ۱۶ لایه‌ی پیچشی استفاده شده است. ساختار هر لایه به این صورت است که تعدادی کانال از ویژگی‌ها (در لایه‌ی اول  خود تصویر) به عنوان ورودی وارد لایه می‌شوند و با استفاده از تعدادی صافی با اندازه $3 \times 3$ به ویژگی‌های خروجی تبدیل می‌شوند. تعداد کانال‌های ورودی در لایه‌ی اول سه کانال رنگی \lr{RGB} است و در لایه‌های بعدی تعداد صافی‌ها به گونه‌ای تعیین شده که تعداد کانال‌های ویژگی‌ها برابر: ۶۴ در لایه‌ی اول و دوم، ۱۲۸ در لایه‌ سوم و چهارم، ۲۵۶ در لایه پنجم تا هشتم و ۵۱۲ در لایه نهم تا شانزدهم است. \gls{ActivationFunction} مورد استفاده در لایه‌های پیچشی تابع \gls{ReLU} است که ضابطه آن به این صورت است:
\begin{equation}
ReLU(\mathbf{x}) = max(\mathbf{0,x}).
\end{equation}
 برای کاهش اندازه ماتریس ویژگی‌ها، میان برخی لایه‌های پیچشی از یک تابع \gls{pooling} استفاده می‌شود. تابع \gls{pooling} مورد استفاده در این شبکه تابع \gls{pooling} بیشینه است یعنی در ماتریس ویژگی‌ حاصل یک پنجره‌ی $2 \times 2$ حرکت داده می‌شود و تنها بزرگترین مقدار میان چهار مقداری پنجره بر آن‌ها منطبق شده به خروجی منتقل می‌شود. بعد از ۱۶ لایه پیچشی سه \gls{fully-connected-layer} وجود دارد. ما برای استخراج ویژگی از خروجی لایه‌ی هفدهم یعنی نخستین  \gls{fully-connected-layer} استفاده می‌کنیم و دو لایه‌ی نهایی کنار گذاشته می‌شوند. ورودی این لایه به این صورت به دست می‌آید که تمام ماتریس‌های ویژگی لایه‌ی شانزدهم به صورت بردارهای یک بعدی در آمده و در کنار هم قرار می‌گیرند، سپس به صورت یک برادر $-25088$ بعدی وارد لایه‌ی هفدهم شده و در این لایه با استفاده از یک نگاشت خطی و \gls{ActivationFunction}   \gls{ReLU} به بردارهای ویژگی $-4096$بعدی تبدیل می‌شود. در شبکه اصلی خروجی این لایه به یک لایه‌ی مشابه خود و در نهایت با یک  \gls{fully-connected-layer} که خروجی آن به اندازه تعداد دسته‌هاست با  \gls{ActivationFunction}
 \lr{softmax}
 به پیش‌بینی برچسب تبدیل می‌شود.

\section{یک شبکه‌عصبی چندوظیفه‌ای}\label{nn}
\begin{figure}[!t]
\centering
\includegraphics[width=0.85\linewidth]{images/net}
\caption[شبکه‌ی چندوظیفه‌ای پیشنهادی]{
ساختار شبکه چند وظیفه‌ای پیشنهادی. فلش‌های آبی رنگ ورودی‌های شبکه را نشان می‌دهند و فلش‌های قرمز رنگ مقایسه خروجی شبکه با خروجی مورد انتظار را. خطوط سیاه‌رنگ اتصالات شبکه‌ را نشان می‌دهند. زیر شبکه‌ی برگرفته شده از شبکه vgg و یک لایه‌ی با اتصالات چگال اضافه شده بین دو دو ورودی مشترک هستند. لایه‌های $r$ و $q$ مخصوص نمونه‌های آزمون هستند. خروجی لایه‌ی $r$ همواره با مقدار صفر مقایسه می‌شود.
}
\label{fig:nn2}
\end{figure}

یادگیری نگاشت‌ها با استفاده از داده‌های دسته‌های دیده‌شده، همان‌طور که در بخش \ref{lr:semi} اشاره شد، دچار مشکل جابجایی دامنه است و  برای داده‌های دسته‌های دیده‌نشده به خوبی قابل تعمیم نیست. یک راه حل برای مقابله با این مشکل این است که در حین یادگیری نگاشت اجبار شود که حاصل نگاشت یک نمونه‌ی آزمون به نوعی نزدیک به نگاشت توصیف یکی از دسته‌های آزمون باشد. همان ‌طور که در بخش
\ref{lr:semi}
بیان شد، چنین راه‌حلی در
\cite{Kodirov2015}
استفاده شده است. معیار نزدیکی نگاشت‌ها در آن روش یک امتیاز پیشین از شباهت هر نمونه‌ی آزمون با دسته‌های دیده نشده است که  توسط روش دیگری استخراج شده است. یعنی ابتدا یک روش دسته‌بندی
احتمالی  (در آن پژوهش روش \lr{IAP} \cite{lampert09} برای این کار انتخاب شده) به صورت مستقل روی مجموعه دادگان اجرا شده و احتمال‌هایی که برای انتساب هر نمونه به دسته‌های آزمون از آن روش بدست می‌آید بعنوان وزن‌های شباهت در نظر گرفته می‌شود. فاصله بردار صفت پیش‌بینی شده برای هر نمونه با توصیف دسته‌های آزمون متناسب با این وزن‌های شباهت جریمه می‌شود.
 ما در این بخش یک روش مبتنی بر شبکه‌های عصبی ژرف معرفی می‌کنیم که در آن نگاشتی غیرخطی و چندلایه از تصاویر به بردارهای صفت یادگرفته می‌شود. معیار یادگیری این نگاشت، پیش‌بینی صحیح صفت برای نمونه‌های آموزش (که بردار صفت صحیح برای آن‌ها مشخص است) و هم‌چنین نزدیک بودن حاصل نگاشت هر نمونه‌ی آزمون به توصیف یکی از دسته‌های دیده نشده است. برای مدل کردن این نگاشت، از یک شبکه‌ی عصبی استفاده شده است. اگر نگاشت مدل شده با شبکه عصبی را با $f$ نشان دهیم، آن‌گاه
 $\mathbf{\hat{c}}_i = f (\mathbf{x}_i) $
 نشان‌دهنده‌ی بردار توصیف پیش‌بینی شده برای نمونه‌ی $-i$م است و
  تابع هزینه‌ی مورد استفاده برای آموزش شبکه به صورت زیر تعریف می‌شود:
\begin{equation}
\label{eq:nn_loss}
\min_{f}
\frac{1}{N_s} \sum_{i=1}^{N_s} loss(\mathbf{\hat{c}}_i, \mathbf{c}_{y_i}) +
\frac{\gamma}{N_u} \sum_{i=N_s}^{N_s+N_u} \Big ( \min_{j=n_s,\ldots,n_s + n_u} \normtwo{\mathbf{\hat{c}_i - c_j}} \Big ),
\end{equation}
که $\gamma$ یک \gls{hyperparameter} است.
جمله‌ی اول، جمله‌ی مربوط به خطای پیش‌بینی صفت‌هاست و تفاوت میان صفات پیش‌بینی شده توسط شبکه و صفات صحیح را برای نمونه‌های آموزش جریمه می‌کند.
 جمله‌ی دوم برای رفع مشکل جابجایی دامنه طراحی شده است و تحمیل می‌کند که حاصل نگاشت یک نمونه‌ی آزمون حتما نزدیک توصیف یکی از دسته‌های دیده‌نشده باشد. این دسته‌ی دیده نشده، دسته‌ای در نظر گرفته شده است که توصیف آن با $\mathbf{\hat{c}}$ کمترین فاصله را دارد. این قسمت از رابطه فوق را می‌توان به صورت شهودی این گونه توضیح داد که در غیاب جمله‌ی دوم رابطه \eqref{eq:nn_loss} برای هر نمونه یک بردار توصیف پیش‌بینی می‌شد و سپس نزدیک‌ترین بردار توصیف از میان توصیف دسته‌های آزمون به عنوان توصیف صحیح در نظر گرفته شده و برچسب بر اساس آن پیش‌بینی می‌شد. حال جمله‌ی دوم رابطه \eqref{eq:nn_loss} جریمه‌ای به میزان فاصله‌ی توصیف پیش‌بینی شده برای هر نمونه با بردار توصیف همان دسته‌ای که به آن نزدیک‌تر است، در نظر می‌گیرد. حال اگر این فرض صحیح باشد که
 حاصل نگاشت در اکثر موارد به توصیف صحیح نزدیکتر است، یا به عبارتی در اکثر مواقع استفاده از دسته‌بند نزدیکترین همسایه روی نگاشتی که تنها با جمله‌ی اول آموزش دیده، دقتی بیش از ۵۰٪ داشته باشد، وجود چنین جمله‌ای باعث می‌شود که مواردی که قبلا درست تشخیص داده می‌شدند حالا با دقت بیشتر (فاصله کمتر از بردار توصیف دسته‌ی مورد نظر) باز هم درست پیش‌بینی شوند. با توجه به افزایش دقت نگاشت روی این نمونه‌ها، انتظار می‌رود برای برخی نمونه‌هایی که در حالت قبل پیش‌بینی نادرست به آن‌ها تعلق می‌گرفت نیز، با این نگاشت بهبود یافته، پیش‌بینی صحیح صورت بگیرد.

 تابع $loss(\cdot, \cdot)$ در معادله \eqref{eq:nn_loss} در مجموعه دادگانی که صفات دودویی هستند تابع \gls{crossentropy} در نظر گرفته شده است یعنی:
 \begin{equation}
 loss(y,z) = z \log(1-y) + (1-z) \log(y).
 \end{equation}
 برای مجموعه دادگانی که مقادیر بردارهای توصیف در آن‌ها مقادیر دلخواه حقیقی است تابع هزینه مربع اختلاف در نظر گرفته شده است:
 \begin{equation}
 loss(y,z) = \normtwo{y-z}.
 \end{equation}
 \subsection{بهینه‌سازی }\label{opt_nn}

 تابع کمینه به کار برده شده در جمله‌دوم معادله
\eqref{eq:nn_loss}
در برخی نقاط مشتق‌پذیر نیست، اما با توجه به اینکه اندازه‌ی این نقاط صفر است تابع تقریبا همه‌جا مشتق‌پذیر است و آموزش شبکه با استفاده از \gls{backprop}
 مقدار گرادیان ممکن خواهد بود. به صورت دقیق‌تر، برای بهینه‌سازی رابطه \eqref{eq:nn_loss} عملیات محاسبه‌ی مقدار کمینه را داخل شبکه تعبیه می‌کنیم (شکل \ref{fig:nn2})؛ به این صورت که لایه‌های جدید $q$ و$r$ برای نمونه‌های دیده نشده اضافه می‌شود که:
\begin{align}
\label{eq:min_layer}
\big(q(\mathbf{v})\big )_j &=  \normtwo{f(\mathbf{v) - c_j}}, \\
r(\mathbf{z}) &= \min_{j=1\ldots n_u} (\mathbf{z})_j.
\end{align}
در رابطه \eqref{eq:min_layer}، لایه‌ی $q$ یک بردار توصیف پیش‌بینی شده را به عنوان ورودی دریافت کرده است و خروجی آن برداری است که تعداد ابعادش برابر تعداد دسته‌های دیده‌نشده است و مقدار هر بعد آن برابر فاصله‌ی بردار $v$ با بردار توصیف (امضای) یک دسته‌ی دیده‌نشده‌است.
 سپس خروجی این لایه به لایه‌ی $r$ وارد می‌شود و در این لایه کوچکترین مقدار این بردار انتخاب می‌شود. نتیجتاً ترکیب این دولایه کمینه‌ی فاصله‌ی $v$ با امضاهای دسته‌های دیده‌نشده را تولید خواهد کرد که برابر جمله‌ی دوم در رابطه \eqref{eq:nn_loss} خواهد بود.

در هنگام آموزش با پس‌انتشار، مشتق تابع هزینه‌ی $l$ نسبت به هر ورودی مثل $z$ در لایه‌ی $r$ با ضابطه‌ی زیر محاسبه می‌شود:
\begin{equation}
\label{eq:grad_min}
\frac{\partial l}{\partial z} = \sum_j \mathds{1}[(z)_j=\min(z)]  \frac{\partial l}{(z)_j}.
\end{equation}

پس از آموزش شبکه، در فاز آزمون لایه‌های $q$ و $r$ حذف شده و بردار توصیف برای تصاویر آزمون با استفاده از شبکه پیش‌بینی می‌شود، در نهایت دسته‌بندی با استفاده از دسته‌بند نزدیک‌ترین همسایه روی نمونه‌های آزمون انجام خواهد شد.

مراحل آموزش شبکه در الگوریتم \ref{alg:nn} آورده شده است.
\شروع{program}[t!]
	\begin{enumerate}[label={\arabic*},itemsep=.1em, parsep=.1em]
\فقره {\bf ورودی:} تصاویر و توصیف‌های آموزش و آزمون و برچسب‌های نمونه‌های آموزش.
\فقره {\bf خروجی:} برچسب‌های پیش‌بینی شده برای نمونه‌های آزمون.
\فقره پیش آموزش شبکه تنها با نمونه‌های آموزش و مقایسه خروجی با توصیف صحیح.
\فقره آموزش کامل شبکه با داده‌های آموزش و آزمون.
\فقره حذف لایه‌های $r$ و $q$.
\فقره خروجی شبکه را به ازای $X_u$ در $P_u$ بریز.
\فقره دسته‌بند نزدیک‌ترین همسایه $NN$ را با بردارهای توصیف دسته‌های آزمون بساز
\فقره عناصر $P_u$ را با استفاده از $NN$ دسته‌بندی کن.
\فقره حاصل مرحله قبل را به عنوان پیش‌بینی نهایی برگردان.
\end{enumerate}
\caption{الگوریتم آموزش و آزمون شبکه عصبی پیشنهادی}
\label{alg:nn}
\پایان{program}
\subsection{معماری شبکه}\label{net_architechture}
ما از قسمتی از شبکه‌ی ۱۹ لایه‌ی \lr{vgg} \cite{vgg} که شامل ۱۶ لایه‌ی پیچشی ابتدا و لایه‌‌‌اول با اتصالات چگال است به عنوان یک زیر شبکه در ورودی شبکه خود استفاده می‌کنیم. همان‌طور که در بخش
\ref{cnns}
شرح داده شد،
 با این زیر شبکه تصاویر ورودی به بردارهای $-4096$بعدی نگاشته می‌شوند.
  سپس یک لایه‌ی با اتصالات چگال قرار دارد که این بردار را به بردارهای توصیف دسته‌ها می‌نگارد. برای نمونه‌های آموزش، خروجی این لایه با بردار توصیف صحیح مقایسه می‌شود. برای نمونه‌های آزمون خروجی این لایه به  لایه‌های  $q$ و$r$ متصل می‌شود و مقدار خروجی $r$ با مقدار مطلوبش که صفر است مقایسه خواهد شد.

\gls{ActivationFunction} در همه‌ی لایه‌ها تابع \gls{ReLU} است؛ با این استثنا که برای مجموعه‌ دادگانی که بردار توصیف دودویی دارند، در لایه‌ی آخر از تابع سیگموید با ضابطه
\begin{equation}
\sigma(x) = \frac{1}{1 + e^{-x}},
\end{equation}
بعنوان \gls{ActivationFunction} استفاده شده است تا مقادیر در بازه‌ی $[0,1]$ نگاشته شوند.

\subsection{یک مدل پایه برای مقایسه}\label{nn_basic}
برای روشن شدن تاثیر استفاده از اطلاعات بدون نظارت نمونه‌های آزمون در یادگیری بهتر نگاشت، قصد داریم در فصل آتی مدل ارائه شده را با یک مدل ساده برای پیش‌بینی صفت مقایسه کنیم که در این‌جا این مدل پایه را معرفی می‌کنیم. در این مدل ساده تنها  از
\glspl{fully-connected-layer}
بعد از استخراج ویژگی با لایه‌های پیچشی، برای پیش‌بینی صفت استفاده شده است. ساختار این مدل در تصویر \ref{fig:nn_basic} نمایش داده شده است. در این شبکه از یک یا چند
\gls{fully-connected-layer}
بعد از لایه‌های پیچشی استفاده می‌شود. مشابه حالت قبل \gls{ActivationFunction} برای مجموعه دادگانی که مقادیر توصیف دسته‌هایشان دودویی است تابع سیگموید، و برای مجموعه دادگانی که مقادیر بردارهای توصیف در آن‌ها مقادیر دلخواه حقیقی است تابع \gls{ReLU} درنظر گرفته شده است.
ابعاد  \glspl{fully-connected-layer} پایانی الزاما برابر تعداد ابعاد بردارهای توصیف است و برای سایر   \glspl{fully-connected-layer} نیز همین تعداد ابعاد انتخاب شده است.
مقایسه نتایج دقت دسته‌بندی بین مدل قبلی و این مدل در بخش \ref{exp:nn} نشان‌دهنده‌ی تاثیر مثبت استفاده از اطلاعات بدون نظارت موجود در نمونه‌های آزمون است که باعث بهبود حداقل ۱۰ درصدی دقت دسته‌بندی  می‌شود.
\begin{figure}[!ht]
\centering
\includegraphics[width=0.4\linewidth]{images/basic_net}
\caption[شبکه‌ی پایه برای پیش‌بینی صفت]{
ساختار شبکه پایه. فلش آبی رنگ ورودی‌های شبکه را نشان می‌دهند و فلش‌های قرمز رنگ مقایسه خروجی شبکه با خروجی مورد انتظار را.}
\label{fig:nn_basic}
\end{figure}

\section{نگاشت به هیستوگرام دسته‌های دیده‌شده با شبکه عصبی} \label{hist}
با توجه به عمل‌کرد خوب نمایش تصاویر و توصیف دسته‌های آزمون به صورت  هیستوگرام دسته‌های دیده شده، به عنوان  فضای میانی برای نمایش تصاویر و توصیف‌ها  در اخیرترین روش‌های یادگیری صفرضرب  \cite{sse}،
در این بخش روشی برای استفاده از این فضای میانی معرفی می‌کنیم. این روش می‌تواند نتایج بهتری نسبت به حالتی که از فضای توصیف‌ها به عنوان فضای مشترک استفاده شده و پیش‌بینی صفت از تصاویر صورت می‌گیرد، کسب نماید.
 روش پیشنهادی برای نگاشت تصویر به یک هیستوگرام از دسته‌های دیده‌شده، مبتنی بر دسته‌بندی عادی تصاویر با شبکه‌های عصبی است. پراستفاده‌ترین روش دسته‌بندی چند دسته‌ای با شبکه‌های عصبی، بهره‌گیری از یک لایه با تابع فعال‌سازی \lr{softmax} با اندازه تعداد دسته‌ها، به عنوان لایه‌ی آخر شبکه است. ضابطه این تابع را که در معادله \eqref{softmax} ذکر شد در این‌جا برای پیگیری بهتر بحث تکرار می‌کنیم. اگر مقادیر لایه‌ی آخر شبکه را با $\mathbf{z} $ نمایش دهیم، با اعمال این تابع فعال‌سازی روی این لایه، عنصر $-j$م آن به این صورت تغییر می‌کنید.
 \begin{equation*}
 softmax(\mathbf{z} )_j = \frac{e^{\mathbf{z} _j}}{\sum_k e^{\mathbf{z} _k}}, \quad j = 1, \ldots, n_s.
 \end{equation*}
با دقت در ضابطه این تابع مشاهده می‌شود که این تابع نسبت هر عنصر را به جمع سایر عناصر حساب می‌کند که به تعبیری برابر با میزان وزنی که عنصر $-j$م نسبت به کل وزن‌های موجود در لایه کسب کرده است.
 برای پررنگ‌تر شدن تفاوت، به جای محاسبه‌ی این نسبت میان خود عناصر از یک تابع نمایی برحسب آن‌ها استفاده شده‌است. اندازه این لایه در شبکه‌های عصبی برابر تعداد دسته‌هایی که علاقمند به دسته‌بندی در ‌آن‌ها هستیم در نظر گرفته می‌شود و هر
\gls{node}
از آن متناظر با یکی از دسته‌ها است. در خروجی این لایه، اگر $(\mathbf{z} )_j$ بیشینه به میزان کافی با سایر مقادیر $\mathbf{z} $ تفاوت داشته باشد، مقدار تابع به ازای  $(\mathbf{z} )_j$ بیشینه نزدیک به یک خواهد بود  و برای سایر عناصر $\mathbf{z} $ نزدیک به صفر است. یعنی با استفاده از این تابع فعال‌سازی، خروجی این لایه می‌تواند کدگذاری یکی‌یک برچسب را تولید کند. به همین علت در هنگام آموزش شبکه از تابع هزینه‌ی آنتروپی متقاطع میان $\mathbf{z} $ و نمایش یکی‌یک برچسب صحیح استفاده می‌شود.

از طرفی به علت عمل میانگین‌گیری، مقادیر این تابع روی یک سادک قرار می‌گیرند یعنی به عبارت دقیق‌تر داریم:
\begin{align}
&\forall j, \quad softmax(\mathbf{z} _j) \geq 0, \\
& \sum_j softmax(z_j) = 1.
\end{align}
در نتیجه می‌توان از خروجی این لایه به عنوان برداری از احتمال تعلق نمونه‌ی ورودی به هر دسته یا به عبارت دیگر هیستوگرام دسته‌ها تعبیر کرد. ما از این خاصیت برای نگاشت تصاویر به هیستوگرام دسته‌های دیده‌شده در یادگیری صفرضرب استفاده می‌کنیم. در روش پیشنهادی یک شبکه عصبی عمیق که برای دسته‌بندی در دسته‌های دیده شده می‌سازیم و با استفاده از نمونه‌های دسته‌های دیده‌شده، که همگی دارای برچسب هستند، آن را آموزش می‌دهیم. در نتیجه این شبکه برای هر تصویر ورودی (اعم از تصاویر دسته‌های دیده‌شده یا دیده‌نشده) یک بردار از امتیاز شباهت آن به هر دسته‌ی دیده‌شده یا به عبارتی هیستوگرامی از دسته‌های دیده شده تولید می‌کند.

 همان‌طور که گفته شد تابع فعال‌سازی \lr{softmax} طوری طراحی شده که تفاوت میان مقادیر گره‌ها را بزرگنمایی کرده و خروجی آن نزدیک به کدگذاری یکی‌یک بردار برچسب باشد. این مسئله می‌تواند باعث از بین رفتن اطلاعات شباهت نمونه به دسته‌هایی شود که در رتبه‌های بعد از دسته‌ای که امتیاز بیشینه را کسب کرده قرار دارند \cite{dark}. برای حل این معضل یعنی افزایش کیفیت هیستوگرام بدست آمده و دور کردن خروجی از کدگذاری یکی‌یک، از یک نسخه تغییر یافته از تابع  \lr{softmax} استفاده می‌کنیم:
 \begin{equation}
 \label{tsoftmax}
	softmax_T((z)_j) = \frac{exp((z)_j/T)}{\sum_i exp((z)_i/T)}.
 \end{equation}
ازدیاد پارامتر $T$ در رابطه \eqref{tsoftmax} باعث تفاوت کمتر مقدار خروجی تابع به ازای $(z)_j$ بیشینه با سایر مقادیر شده و خروجی هموارتری نسبت به حالت معمول که در که در آن $T=1$ است تولید می‌کند. ما در زمان آموزش شبکه، به علت این که خروجی با کدگذاری یکی‌یک برچسب صحیح مقایسه می‌شود، از مقدار $T=1$ استفاده می‌کنیم. اما برای بدست آوردن نمایش تصاویر آزمون در فضای هیستوگرام دسته‌های دیده‌شده از مقدار $T>1$ بهره می‌گیریم تا خروجی شبکه میزان شباهت به دسته‌های مختلف را به صورت هموارتر نشان دهد. هیستوگرام حاصل از تصویر $\mathbf{x}$ با این روش را با نماد
 $\psi{(\mathbf{x} )}$ نمایش می‌دهیم. نگاشت $\psi$ که با یک شبکه‌ی عصبی عمیق مدل شده، از سه قسمت تشکیل شده است: ۱) ۱۶ لایه پیچشی شرح داده شده در بخش \ref{cnns}،
۲) سه لایه با اتصالات کامل که وزن‌های آن‌ها با آموزش روی نمونه‌های دسته‌های دیده شده به دست می‌آید و ۳) تابع فعال‌سازی نهایی از رابطه \ref{tsoftmax}.

برای تکمیل روش‌ پیشنهادی برای دسته‌بندی صفرضرب باید نگاشتی برای بردن بردارهای توصیف دسته‌های دیده نشده به این فضا، یعنی فضای هیستوگرام دسته‌های دیده‌شده ارائه کنیم. برای این کار از عکس فاصله‌ی اقلیدسی بردارهای توصیف دسته‌ها با یکدیگر استفاده می‌کنیم، به عبارتی برای بردار توصیف $c$ متعلق به یک دسته‌ی دیده‌نشده داریم:
 \begin{equation}
\theta_j(\mathbf{c}) = \frac{1}{\norm{\mathbf{c - c_j}}_2  }, \quad j=1,\ldots, n_s.
\end{equation}
 دسته‌بندی در این فضا با استفاده از  دسته‌بند نزدیک‌ترین همسایه صورت می‌گیرد، به عبارت دیگر اگر تابع اختصاص برچسب را با $\ell(\cdot)$ نشان دهیم:
\begin{equation}
\ell(\mathbf{x}) = \argmin_{i=n_s, \ldots, n_s+n_u} \normtwo{\psi(\mathbf{x}]) - \theta(\mathbf{c}_i)}.
\end{equation}
در نهایت با استفاده از تابع مطابقتی که در بخش \ref{compatibility_function} معرفی شده، می‌توان نتایج حاصل از دسته‌بند نزدیک‌ترین همسایه را بهبود داد.
%--------------------------------------------------------------------
\section{ تابع مطابقت مبتنی بر خوشه‌بندی }\label{compatibility_function}
در اکثر روش‌های پیشین که در فصل \ref{chap:lr} مرور شد، تابع مطابقت میان تصاویر و توصیف‌ها برای اختصاص برچسب به داده‌های آزمون بر اساس فاصله کمینه یا ضرب داخلی بیشینه در یک فضای مشترک محاسبه می‌شد. استثناهای این موضوع، استفاده از روش انتشار برچسب در \cite{Fu2014} و \cite{Kodirov2015} و هم‌چنین پیش‌بینی مستقیم برچسب‌ها در
\cite{li15max}
و
\cite{semi15}
هستند.

\begin{figure}[!t]
\centering
\includegraphics[width=0.85\linewidth]{images/awa_clusters}
\caption[نمایش دسته‌های آزمون مجموعه دادگان AwA ]{
نمایش دوبعدی بوسیله \lr{t-SNE} برای ده دسته‌ی آزمون از مجموعه دادگان AwA با ده رنگ متفاوت نشان داده شده است. درستی فرض قابل خوشه‌بندی در تصویر مشخص است، یعنی ویژگی‌های استخراج شده با استفاده از شبکه‌های ژرف توانایی ایجاد تمایز بالا میان دسته‌ها را دارا هستند و نمونه‌های هر دسته نیز نزدیک به یکدیگر هستند.
}
\label{fig:awa_clusters}
\end{figure}

در این بخش  یک تابع مطابقت جدید بر اساس یک خوشه‌بندی روی داده‌های دسته‌های دیده نشده، طراحی و پیشنهاد می‌کنیم. اگر فضای نمایش تصاویر، دارای این خاصیت باشد که نمونه‌های دسته‌های مختلف در آن به صورت خوشه‌های مجزا درآیند، استفاده از یک خوشه‌بندی برای انتساب برچسب، از نظر شهودی توجیه‌پذیر است.
با توجه به نمایش غنی بوجود آمده برای تصاویر توسط شبکه‌های ژرف این فرض در بسیاری از موارد برقرار است. برای نمونه، نمایش \lr{t-SNE} نمونه‌های آزمون مجموعه داده‌های AwA در تصویر
\ref{fig:awa_clusters}
نشان داده شده است و برقراری فرض قابل خوشه‌بندی بودن در آن قابل مشاهده است. این ادعا با استفاده از آزمایش در بخش
\ref{exp:cluster}
اثبات خواهد شد. روش‌های پیشنهادی ما در بخش‌های آتی بر اساس این ساختار و استفاده از وجود چنین خاصیتی در فضای تصاویر است.
%\section{معرفی یک تابع مطابقت}\label{copatibility_function}

یک راه استفاده از چنین خاصیتی در فضای تصاویر، معرفی یک تابع مطابقت است که علاوه بر شباهت نگاشت‌یافته‌ی نمونه‌ها و توصیف‌ها، سایر نمونه‌های موجود در همسایگی هر نمونه را نیز در نظر بگیرد. بدین منظور ما یک تابع مطابقت جدید پیشنهاد می‌دهیم که در آن برچسب تعلق گرفته به هر نمونه به نمونه‌هایی
 که با آن‌ها در یک خوشه قرار دارد، وابسته است. برای این منظور ابتدا باید یک خوشه‌بندی روی نمونه‌ها انجام شود، سپس با استفاده از یک معیار (که یک نمونه از آن را در بخش \ref{simple_method} معرفی می‌کنیم) میزان شباهت خوشه‌ها به توصیف دسته‌ها تعیین شود. چنین تابع مطابقتی با توابع مطابقت پیشین، که میزان شباهت هر نمونه را به طور جداگانه با توصیف دسته‌ها محاسبه می‌کردند، متفاوت است و همه‌ی نمونه‌ها در تعیین برچسب یکدیگر موثر هستند. در این حالت هر خوشه باید یک برچسب دریافت کند و برچسب اختصاص یافته به هر خوشه، توسط تمام اعضای آن به ارث برده می‌شود. این تابع مطابقت تا کنون در روش‌های موجود برای یادگیری صفرضرب استفاده نشده است. نسخه‌های متفاوتی از این تابع مطابقت، بر حسب چگونگی تعیین برچسب هر خوشه، قابل ارائه است. ما در اینجا دو مورد از آن‌ها را بیان می‌کنیم.
یک شیوه برای انتساب برچسب به  خوشه‌ها، استفاده از رای اکثریت است؛ در این حالت بایست ابتدا یک پیش‌بینی برای همه نمونه‌های آزمون صورت بگیرد (برای مثال با استفاده از روش معرفی شده در بخش \ref{nn})، فرض کنید مقادیر این پیش‌بینی را با
$z_n$
برای
 $N_s < n \leq N_s + N_u$
نشان دهیم. هم‌چنین یک خوشه‌بندی روی داده‌ها انجام شده که آن را با
$r_n$ برای
$N_s < n \leq N_s + N_u$
نشان می‌دهیم. حال   $\ell(k)$ که برچسب خوشه‌ی $-k$م است از رابطه زیر تعیین خواهد شد:
\begin{equation}
\label{eq:voting}
\ell(k) = \argmax_{n_s < i \leq n_s + n_u} \, \Big [ \sum_{m=N_s+1}^{N_s+N_u} \mathds{1}(r_n = k) \times \mathds{1}(z_n = i) \Big ].
\end{equation}
 این نسخه از تابع مطابقت پیشنهادی قابل اضافه شدن به روش‌های دیگر نیز هست. به این صورت که پیش‌بینی‌های انجام شده در آن روش را در نظر گرفته و با استفاده از آن‌ها در هر خوشه رای‌گیری انجام دهیم تا برچسبی که کل خوشه دریافت می‌کند تعیین شود. برای نمونه این تابع مطابقت را بر خروجی شبکه چندوظیفه‌ای پیشنهادی اعمال می‌کنیم. در بخش 
 \ref{exp:nn}
 نشان داده خواهد شد
  که  اضافه شدن این تابع مطابقت عمل‌کرد آن‌ را بهبود می‌دهد.

 یک نسخه‌ی دیگر از این تابع مطابقت، که در روش ارائه شده در بخش \ref{simple_method} مورد استفاده قرار می‌گیرد، مربوط به حالتی است که نگاشتی از فضای توصیف دسته‌ها به فضای تصاویر وجود داشته باشد. فرض کنید که چنین نگاشتی یادگرفته شده و با $\theta$ نشان داده شود. هم‌چنین نگاشت
 $\phi(x)$
  نگاشت تبدیل تصاویر به ویژگی‌های ژرف است. مانند حالت قبل یک خوشه‌بندی $r_n$ روی نمونه‌های آزمون صورت گرفته و
   $\boldsymbol{\mu_k} $
    مرکز خوشه $-k$م را نشان می‌دهد. در نتیجه داریم:
 \begin{equation}
 r_n = \argmin_{k} \normtwo{\phi(\mathbf{x_n}) - \boldsymbol{\mu_k}}.
 \end{equation}
 حالا میزان مطابقت نمونه‌ی $\mathbf{x_n} $ و توصیف $\mathbf{c} $ با استفاده از رابطه زیر تعریف می‌شود:
 \begin{equation}
 compatibility(\mathbf{x,c}) = - \norm{\boldsymbol{\mu_{r_n}} -  \theta(\mathbf{c})}_2.
 \end{equation}
 تعبیر رابطه فوق این است که میزان مطابقت نمونه $\mathbf{x} $ با دسته‌ی آزمون $y$، بر اساس میزان نزدیکی مرکز خوشه‌ای که $\mathbf{x} $ به آن تعلق دارد با تصویر توصیف دسته‌ی $y$ در فضای ویژگی‌های تصاویر تعریف می‌شود.


%-----------------------------------------------------------Section -----------
\section{یک خوشه‌بندی نیمه‌نظارتی}\label{clustering_method}
عمل‌کرد تابع مطابقت معرفی شده در بخش قبل، وابسته به دقت خوشه‌بندی انجام شده روی داده‌هاست. در واقع دقت خوشه‌بندی انجام شده، حد بالای دقت نهایی روش خواهد بود؛ چرا که در تابع مطابقت معرفی شده، تمام اعضای یک خوشه برچسب یکسانی را دریافت می‌کنند در نتیجه اگر اعضای درون یک خوشه هم‌دسته نباشند حداکثر اعضای متعلق به یکی از دسته‌ها برچسب صحیح دریافت می‌کنند و پیش‌بینی برای سایر اعضای خوشه که متعلق به دسته‌های دیگر هستند نادرست خواهد بود.
 این حد بالا  در حالتی رخ می‌دهد که هر خوشه برچسبی را دریافت کند که برچسب صحیح  اکثر اعضای آن است. با توجه به این موضوع وجود یک خوشه‌بندی دقیق برای استفاده از این تابع مطابقت ضروری است. البته در آزمایش‌های انجام شده، با به کارگیری تابع مطابقت پیشنهادی و استفاده از  الگوریتم خوشه‌بندی
\lr{k-means} \cite{kmeans}
نیز می‌توان به عمل‌کرد پیشگام دست پیدا کند. اما این الگوریتم در خوشه‌بندی نمونه‌های آزمون، استفاده‌ای از برچسب‌هایی که برای نمونه‌های آموزش وجود دارد، نخواهد کرد. این درحالی است که  اطلاعات بانظارت موجود در نمونه‌های آموزش می‌تواند باعث بهبود عمل‌کرد خوشه‌بندی شود. از طرفی الگوریتم‌های نیمه‌نظارتی موجود برای خوشه‌بندی بر مسئله یادگیری صفرضرب تطابق ندارند. در حالت معمول یادگیری نیمه‌نظارتی \cite{chapel06}، مسئله به این صورت تعریف می‌شود که داده‌های برچسب‌دار و بدون برچسب همگی به یک مجموعه دسته‌ی یکسان تعلق دارند و داده‌های بدون برچسب در نهایت در خوشه‌هایی قرار می‌گیرند که داده‌های برچسب‌دار نیز به آن خوشه‌ها تعلق دارند. این در حالی‌ست که در مسئله یادگیری صفرضرب، نمونه‌های بدون برچسب در دسته‌های مجزا از نمونه‌های برچسب‌دار قرار می‌گیرند. با توجه به این موضوع، یک روش خوشه‌بندی نیمه‌نظارتی پیشنهاد می‌کنیم که با فرض‌های مسئله یادگیری صفرضرب منطبق باشد. در این روش خوشه‌بندی همانند k-means عمل می‌شود با این تفاوت که اگر شماره خوشه نمونه‌های دسته‌های دیده شده  برابر با برچسب صحیح آن‌ها نباشد، جریمه‌ای در نظر گرفته می‌شود. تابع هزینه این روش به این صورت تعریف شده است:
\begin{equation} \label{eq:my_clustering}
\min_{R, \boldsymbol{\mu_1, \ldots, \mu_k }}  \sum_{n,k} r_{nk} \normtwo{\mathbf{x_n} - \boldsymbol{\mu_k}} +
 \beta \sum_{n=1}^{N_s} \mathds{1}(\mathbf{r_n} \neq \mathbf{y_n}).
\end{equation}
در این معادله $ \boldsymbol{\mu_1, \ldots, \mu_k }$ مراکز خوشه‌ها و $R$ ماتریس اختصاص داده‌ها به خوشه‌هاست؛ جمله اول همان جمله موجود در تابع هزینه‌ی
\lr{k-means}
است. علاوه بر این، در جمله‌ی دوم برای هر نمونه‌ی برچسب‌دار، اگر به خوشه‌ای تعلق بگیرد که شماره آن با برچسبش متفاوت باشد، جریمه $\beta$ در نظر گرفته می‌شود. در نتیجه این روش، $n_s$ خوشه ابتدایی را به سمت این سوق می‌دهند که همان $n_s$ دسته‌ی دیده شده باشند.  $\beta$ یک \gls{hyperparameter} مدل است که اهمیت این جمله اضافه شده را تعیین می‌کند.

\subsection{بهینه‌سازی}\label{simple_opt}
 کمینه‌کردن تابع هزینه معرفی شده در رابطه
\eqref{eq:my_clustering}،
با توجه به این که $R$ یک \gls{partitioning} روی نمونه‌هاست، مانند بهینه‌سازی تابع هزینه‌ی \lr{k-means} یک مسئله‌ی \nphard است \cite{kmeans_nphard}. در نتیجه ما از یک تقریب
مشابه الگوریتم خوشه‌بندی \lr{k-means} استفاده می‌کنیم که یک بهینه محلی برای این تابع را پیدا می‌کند. به این منظور،  یک روند \gls{alternative}  میان بهینه کردن بر اساس $R$ و $\mu_k$ها به کار گرفته می‌شود. برای بروز رسانی $\mu_k$ روی اعضای خوشه $k$ میانگین گرفته می‌شود:
\begin{equation} \label{eq:updata_mu}
 \boldsymbol{\mu_k} = \frac{\sum_{n=1}^{N_s + N_u}  \mathds{1}(r_{nk}=1)\mathbf{x_n}}{\sum_{n=1}^{N_s+N_u}\mathds{1}(r_{nk}=1)}.
\end{equation}
برای بروز رسانی $R$ هر نمونه که متعلق به دسته‌های دیده‌نشده است و برچسب صحیحی برای آن موجود نیست، به خوشه‌ای اختصاص می‌یابد که کمترین فاصله را با مرکز آن دارد:
\begin{equation} \label{eq:updata_R}
R_{(n)} = \mathbf{1}_{\argmin_k \normtwo{x_n - \mu_k}}, \quad n=N_s+1,\ldots,N_s+N_u
\end{equation}
اما برای نمونه‌های دسته‌های دیده شده که برچسب صحیحی برای آن‌ها موجود است علاوه بر فاصله تا مرکز خوشه مقدار جمله دوم رابطه \eqref{eq:my_clustering} نیز در تخصیص خوشه موثر است. در این حالت تخصیص نمونه به خوشه‌ای با شماره‌ای متفاوت با برچسب صحیحش، جریمه‌ای به مقدار $\beta$ خواهد داشت.
\begin{align}\label{eq:updata_R2}
R_{(n)} = \mathbf{1}_{\argmin_k \normtwo{x_n - \mu_k} + \beta \mathds{1}(y_n \neq 1_k)}, \quad n=1,\ldots,N_s
\end{align}

برای مقداردهی اولیه به $\mu_k$ برای  خوشه‌های مربوط به دسته‌های دیده شده، میانگین عناصر آن‌ها را قرار می‌دهیم:
\begin{equation} \label{eq:init_mu}
 \boldsymbol{\mu_k^0} = \frac{\sum_{n=1}^{N_s}  \mathds{1}(Y_{s(n)} = \mathbf{1_k})\cdot \mathbf{x_n}}{\sum_{n=1}^{N_s}\mathds{1}(Y_{s(n)} = \mathbf{1_k})},
\quad 1 \leq k \leq n_s
\end{equation}
که $\boldsymbol{\mu_k^0} $ برای نشان دادن مقدار در لحظه‌ی صفر یا همان مقدار اولیه برای شروع الگوریتم بهینه‌سازی بکار رفته است.
برای سایر خوشه‌ها، یعنی خوشه‌های مربوط به دسته‌های دیده نشده از الگوریتم
\lr{k-means++ } \cite{kmeanspp}
با $k' = k- n_s$ یعنی تعداد خوشه‌هایی که به جز دسته‌های دیده‌شده وجود دارد،
استفاده می‌کنیم.


% فرض کنید که نمونه‌های $X_u$ با یک روش خوشه‌بندی به $n_u$ خوشه تقسیم شده‌اند و $R$ ماتریس اختصاص خوشه‌ها با نمایش یکی‌یک است.
\section{روش یادگیری صفرضرب خوشه‌بندی و یادگیری نگاشت مجزا} \label{simple_method}
در این بخش روشی معرفی می‌شود که همراه با خوشه‌بندی بخش قبل یک چارچوب برای دسته‌بندی در مسئله یادگیری صفرضرب را تشکیل می‌دهند. برای نسبت دادن برچسب به خوشه‌ها، به دنبال یافتن نمایشی از امضای هر دسته در فضای تصاویر، به عنوان نماینده آن دسته در فضای تصاویر هستیم. از نظر شهودی مطلوب است که این نماینده‌ها بر مرکز خوشه‌هایی که در فضای تصاویر تشکیل می‌شود منطبق باشند. برای محقق شدن این خاصیت، نگاشت را با این معیار یاد می‌گیریم که حاصل نگاشت توصیف هر دسته‌ی آموزش بر میانگین نمونه‌های آن منطبق باشد:
\begin{equation} \label{eq:d_definition}
  D = \argmin_D \normf{X_s - D Z_s}^2 + \alpha \normf{D}^2.
\end{equation}
در این معادله، ستون‌های
 $Z_s \in \mathbb{R}^{a \times N_s}$
  امضای دسته‌های مربوط به نمونه‌های $X_s$ هستند و $\alpha$ یک \gls{hyperparameter} است که با اعتبارسنجی تعیین خواهد شد. مسئله تعریف شده برای یافتن نگاشت $D$، امضای کلاس را طوری می‌نگارد که نزدیک به مرکز نمونه‌های آن دسته باشد و این در حالت ایده‌آل همان مرکز خوشه‌ها خواهد بود. یعنی انتظار می‌رود
  حاصل نگاشت امضای هر دسته با استفاده از $D$ در مرکز نمونه‌های آن دسته قرار بگیرد، از طرفی در یک خوشه‌بندی ایده‌آل خوشه‌بندی سازگار با برچسب‌های صحیح داده‌هاست در نتیجه میانگین اعضای یک خوشه در حقیقت میانگین اعضای یکی از دسته‌های آزمون خواهد بود. حالا تنها گام باقی‌مانده برای تکمیل روش این است که به گونه‌ای تشخیص داده شود که هر کدام از خوشه‌ها با کدام یک از دسته‌های دیده‌نشده در تناظر است برای این کار از دسته‌بند نزدیک‌ترین همسایه استفاده می‌کنیم به این صورت که مراکز خوشه‌ها و حاصل نگاشت امضای دسته‌ها در فضای تصاویر را در نظر گرفته و هر خوشه را به دسته‌ای انتساب می‌دهیم که نمایش  امضای آن دسته در این فضا به مرکز خوشه نزدیک‌تر است.

یافتن نگاشت $D$ بر اساس  کمینه‌کردن رابطه
  \eqref{eq:d_definition}
  به وسیله‌ی یک رابطه فرم بسته قابل انجام است.
  به این منظور از رابطه‌ی \eqref{eq:d_definition} برحسب عناصر $D$ مشتق می‌گیریم و برابر صفر قرار می‌دهیم:
  \begin{align*}
  &\frac{\partial}{\partial D} \normf{X_s - D Z_s}^2 + \alpha \normf{D}^2 =
    \frac{\partial} {\partial D}tr((X_s -DZ_s)^T (X_s-DZ_s)) + \alpha \frac{\partial}{\partial D}tr(D^TD) \\
& = 2(DZ_s - X_s)Z_s^T + 2 \alpha D =0 \\
&\Rightarrow  DZ_sZ_s^T -  X_sZ_s^T + \alpha D =0 \Rightarrow D(Z_sZ_s^T + \alpha I) =  X_sZ_s^T
  \end{align*}
  و در نتیجه خواهیم داشت:
  \begin{equation} \label{eq:d_answer}
  D = X_s Z_s^T (Z_s Z_s^T + \alpha I)^{-1}.
\end{equation}

برای تخصیص برچسب به هر خوشه از این رابطه استفاده می‌کنیم:
\begin{equation}
\label{eq:simple_assignment}
\ell(\boldsymbol{\mu_k}) = \argmin_{u=1,\ldots,n_u} \normf{\boldsymbol{\mu_k} - DC_{u}}^2
\end{equation}
و تمامی عناصر خوشه‌ی $k$م برچسب $\ell(\boldsymbol{\mu_k})$ را دریافت می‌کنند. با توجه به انجام مستقل مراحل خوشه‌بندی و یادگیری نگاشت این روش را
\textit{یادگیری نگاشت و خوشه‌بندی مجزا می‌نامیم}
که با توجه به نوع خوشه‌بندی مورد استفاده (خوشه‌بندی نیمه‌نظارتی پیشنهادی یا الگوریتم \lr{k-means}) ممکن است پسوند نیمه‌نظارتی نیز به آن اضافه شود.

در این روش سه \gls{hyperparameter} وجود دارد، یک پارامتر $\alpha$ در معادله
\eqref{eq:d_definition}
است و دو پارامتر دیگر که مربوط به خوشه‌بندی نیمه‌نظارتی هستند، یعنی $k$ و $\beta$ در معادله
\eqref{eq:my_clustering}.
در آزمایش‌ها عملی دریافتیم که روش به مقدار پارامتر $\alpha$ حساس است در نتیجه مقدار آن توسط یک روند اعتبارسنجی تعیین خواهد شد، نحوه‌ی اعتبارسنجی به صورت دقیق در بخش
\ref{exp:validation}
بیان خواهد شد. در مقابل، مدل به پارامترهای $k$ و $\beta$ حساس نبود، در نتیجه برای ساده و سریع‌تر شدن روند آموزش مقدار آن‌ها را ثابت در نظر گرفته‌ایم. برای $k$ مقدار
$k = n_s + 2n_u$
در نظر گرفته شده است چرا که عموما افزایش تعداد خوشه‌ها نسبت به دسته‌ها می‌تواند دسته‌هایی که الزاما به صورت یک خوشه نیستند را هم مدل کند.
 با ارائه نتایج عملی تاثیر این دو پارامتر در فصل
 \ref{exp:simple}
 نشان داده می‌شود که این انتخاب‌ها، انتخاب‌های تاثیرگذاری نبوده و عمل‌کرد روش به مقدار این دوپارامتر حساس نیست.
در آزمایش‌ها عملی که در فصل
\ref{chap:experiments}
گزارش می‌شود، مشاهده می‌شود که این روش  عمل‌کرد پیشگام در دقت دسته‌بندی صفرضرب را روی سه مجموعه دادگان از چهار مجموعه بهبود می‌بخشد.



روند کامل این روش پیشنهادی در الگوریتم
\ref{alg:simple}
بیان شده است.

\شروع{program}
	\begin{enumerate}[label={\arabic*},itemsep=.1em, parsep=.1em]
\فقره {\bf ورودی:} تصاویر و توصیف‌های آموزش و آزمون و برچسب‌های نمونه‌های آموزش $X_s, X_u, Y_s, Z_s, C_u$
\فقره {\bf خروجی:} برچسب‌های پیش‌بینی شده برای نمونه‌های آزمون:$Y_u$
\فقره  $\boldsymbol{\mu_k}$ را برای  $k=1,\ldots,n_s$،  با رابطه \eqref{eq:init_mu} مقداردهی کن.
\فقره  $\boldsymbol{\mu_k}$ را برای $k=n_s+1,\ldots,n_s+n_u$، با استفاده از \lr{k-means++} مقداردهی کن.
\فقره تا همگرایی به یک بهینه‌ی محلی، موارد زیر را تکرار کن

\فقره
$\qquad$
${\argmin_i \lVert x_n - \mu_i \rVert_2^2} \rightarrow a_n \, $
برای
$\, n = N_s + 1, \ldots, N_s+N_u \,$
\فقره
 $\qquad$
${\argmin_i \lVert x_n - \mu_i \rVert_2^2} + \beta \mathds{1}(y_n \neq 1_i) \rightarrow a_n \, $
برای
 $n = 1, \ldots, N_s \quad$
\فقره
 $\qquad$ $\sum_{n} \mathbf{x_n} \mathds{1}(a_n = k) / \sum_n (\mathds{1}(a_n = k) \rightarrow \mathbf{\mu_k}$

\فقره
 $X_s Y_s^T (Y_s Y_s^T + \alpha I)^{-1} \rightarrow D\quad$
 برای
 $\quad k \in \{1,2,\ldots, n_s + n+u\}$
\فقره
 $\argmin_j \lVert \mathbf{\mu_k} - (DS_u)_{(j)} \rVert_2 \rightarrow l[k] \quad$
 برای
 $\quad k \in \{1,2,\ldots, n_s + n+u\}$
\فقره
   $ \mathbf{1}_{l[a_n]} \rightarrow \mathbf{(Y_u)_{(n)}}  \quad$
   برای
   $\quad n \in \{ N_s +1 \ldots N_s + N_u \}$
\فقره $Y_u$ را برگردان
\end{enumerate}
\caption{الگوریتم یادگیری صفرضرب خوشه‌بندی و یادگیری نگاشت مجزای نیمه‌نظارتی}
\label{alg:simple}
\پایان{program}


%-------------------------------------------------- section
\section{خوشه‌بندی و نگاشت توام} \label{jeac}
روش ارائه شده در فصل قبل، هر چند که به دقت دسته‌بندی بالاتری از روش‌های پیشین دست پیدا می‌کند اما دقت دسته‌بندی در آن توسط دقت خوشه‌بندی صورت گرفته محدود شده است. هم‌چنین انجام جداگانه عمل خوشه‌بندی و یادگیری نگاشت از فضای توصیف‌ها به فضای تصاویر امکان استفاده از کامل از اطلاعات برای یادگیری توام و سازگاری بین این دو یادگیری را از بین می‌برد. این درحالی است که با توجه به وجود داده‌های برچسب‌دار از دسته‌های دیده شده، یادگیری توام این دو قسمت یعنی خوشه‌بندی و نگاشت از فضای توصیف‌ها به فضای تصاویر می‌تواند باعث شود که اختصاص نمونه‌های آزمون به خوشه‌ها به گونه‌ای انجام شود که همزمان هر دو معیار شبیه بودن به سایر نمونه‌های درون خوشه (که تنها در مرحله خوشه‌بندی روش قبلی در نظر گرفته می‌شد) و معیار نزدیکی نمونه‌های یک خوشه به حاصل نگاشت توصیف دسته‌ی آن‌ها (که تنها در مرحله یادگیری نگاشت دیده می‌شد) در نظر گرفته شوند.
 برای دست‌یابی به چنین هدفی یک مسئله بهینه‌سازی معرفی می‌کنیم که خوشه‌بندی و نگاشت توصیف دسته‌ها به فضای تصاویر در آن به صورت توام انجام شود:
\begin{align}
\label{eq:joint}
 \min_{R,D} \normf{X_s - D Z_s}^2  &+ \lambda \normf{X_u - D C_u R^T }^2 + \eta \normf{D}^2, \\
   s.t. \quad & R \in \{0,1\}^{N_u \times n_u}. \nonumber
\end{align}
در این معادله $\eta$ و $\lambda$ فراپارامترهای مدل هستند. جمله اول و سوم در رابطه بالا مشابه رابطه \eqref{eq:d_definition} هستند و تاثیر آن‌ها همانند حالت قبل این است که نگاشت $D$ بتواند امضای دسته‌های دیده نشده را به مرکز تصاویر هر دسته بنگارد. جمله دوم که در این معادله اضافه شده، ذاتا یک جمله خوشه‌بندی است. اگر جمله دوم در عبارت بالا را از فرم ماتریسی خارج کرده و بر حسب عناصر $R$ بیان کنیم این مسئله واضح‌تر  خواهد شد:
\begin{equation}
\label{eq:essentialy_clustering}
\sum_{n=N_s+1}^{N_s + N_u} \sum_{k=1}^{n_u} r_{nk} \normtwo{\mathbf{x_n} - D \mathbf{c_k}},
\end{equation}
که مشابه تابع هزینه‌ی
\lr{k-means}
است، با این تفاوت که مراکز خوشه‌ها کاملا آزاد نیستند بلکه مراکز خوشه‌ها باید تصویر امضای دسته‌های دیده نشده باشد که توسط نگاشت $D$ به فضای تصاویر نگاشته شده است. در این حالت برچسب‌های پیش‌بینی شده برای نمونه‌ها همان انتساب‌های آن‌ها به خوشه‌هاست که در طول جریان آموزش توامان با نگاشت $D$ یادگرفته می‌شود. در نتیجه مشکل بیان شده برای روش قبل، در این روش وجود ندارد. جمله خوشه‌بندی را در این مسئله بهینه‌سازی می‌توان به این صورت نیز تعبیر کرد که این جمله یادگیری نگاشت $D$ را به صورتی بهبود می‌دهد که مشکل جابجایی دامنه در آن وجود نداشته باشد. در حالت عادی برای یادگیری نگاشت $D$ توسط رابطه
\eqref{eq:d_definition}
تنها از نمونه‌های آموزش استفاده می‌شد، در نتیجه مشکل جابجایی دامنه برای داده‌های آزمون بوجود می‌آمد، چرا که این داده‌ها در تعیین نگاشت $D$ بی‌تاثیر بوده‌اند. اما جمله اضافه شده در روش فوق الزام می‌کند که امضای هر دسته‌ی دیده نشده نزدیک به تعدادی از داده‌های آزمون (که توسط $R$ مشخص می‌شوند) نگاشته شود. این مسئله می‌تواند مانع از مشکل جابجایی دامنه شود. این موضوع در بخش
\ref{exp:discussion}
بیشتر بررسی خواهد شد.
\subsection{بهینه‌سازی}\label{jeac_opt}

\شروع{program}[t!]
	\begin{enumerate}[label={\arabic*},itemsep=.1em, parsep=.1em]
\فقره {\bf ورودی:} تصاویر و توصیف‌های آموزش و آزمون و برچسب‌های نمونه‌های آموزش $X_s, X_u, Y_s, Z_s, C_u$
\فقره {\bf خروجی:} برچسب‌های پیش‌بینی شده برای نمونه‌های آزمون:$R$
\فقره $R$ را با خروجی الگوریتم \ref{alg:simple} مقدار دهی کن.
\فقره تا هنگامی که مقدار $R$ تغییر می‌کند،  تکرار کن:
\فقره $\qquad$  $D$ را با رابطه \eqref{eq:joint_d_update} بروزرسانی کن.
\فقره $\qquad$ عناصر $R$ را با استفاده از رابطه \eqref{eq:joint_r_update} بروزرسانی کن.
\فقره $R$ را برگردان
\end{enumerate}
\caption{الگوریتم یادگیری نگاشت و خوشه‌بندی به صورت توام}
\label{alg:jeac}
\پایان{program}

مسئله بهینه‌سازی رابطه \eqref{eq:joint} بر حسب هر دو متغیر $R$ و $D$
\gls{convex}  نیست، در نتیجه برای یافتن یک بهینه محلی از یک روند تناوبی میان بهینه‌کردن بر حسب $R$ و $D$ استفاده می‌کنیم.
با فرض ثابت بودن $R$ بهینه‌سازی بر اساس $D$ دارای جواب به فرم بسته است، برای بدست آوردن این جواب نسبت به عناصر $D$ از رابطه \eqref{eq:joint} مشتق می‌گیریم:
\begin{align*}
& \frac{\partial}{\partial D}\normf{X_s - D Z_s}^2  + \lambda \normf{X_u - D C_u R^T }^2 + \eta \normf{D}^2 \\
& =2 (DZ_s - X_s)Z_s^T + \lambda (DC_uR^T - X_u) RC_u^T + \eta D = 0 \\
& \Rightarrow D(Z_sZ_s^T + C_uR^TRC_u^T + \eta I) - X_sZ_s^T + X_uRC_u^T  = 0
\end{align*}
در نتیجه خواهیم داشت:
\begin{equation} \label{eq:joint_d_update}
  D = (X_s Z_s^T + \beta X_u R C_u^T) (Z_s Z_s^T + \beta C_u R^T R C_u^T  + \eta I)^{-1},
\end{equation}
و مقدار بهینه برای $R$، زمانی که $D$ ثابت باشد، با نسبت دادن هر نمونه به نزدیک‌ترین مرکز خوشه به دست می‌آید:
\begin{equation} \label{eq:joint_r_update}
  r_{ij} = \mathds{1}[j = \argmin_{k} \lVert X_{u(i)} - D S_{u(k)} \rVert_2 ].
\end{equation}
در این روند بین بروز رسانی $D$ و $R$ تناوب انجام می‌شود تا جایی که $R$ ثابت بماند یعنی تغییری در برچسب‌های پیش‌بینی شده برای هیچ‌کدام از نمونه‌ها رخ ندهد. در آزمایش‌های انجام شده این همگرایی همواره در کمتر از ۲۰ بار بروز رسانی به دست می‌آید.

مراحل این روش در الگوریتم \ref{alg:jeac} آمده است. در مورد گام ۳ از این الگوریتم این توضیح لازم است که از میان $R$ و $D$ تنها یکی نیاز به مقداردهی اولیه دارد؛ چرا که روابط بروز رسانی هر کدام تنها به مقدار پارامتر دیگر بستگی دارد و از مقدار پیشین خود مستقل است. در نتیجه در روند بهینه‌سازی تناوبی هرکدام از $R$ و $D$ که ابتدا بروز رسانی شوند، در بروز رسانی آن‌ها تنها به مقدار اولیه پارامتر دیگر نیاز است و خود آن نیاز به مقداردهی اولیه ندارند. ما در اینجا $R$ را مقداردهی اولیه کرده و روند بهینه‌سازی را با بروزرسانی $D$ آغاز می‌کنیم. این انتخاب نسبت به حالت مقابلش یعنی مقداردهی اولیه $D$ با رابطه
\eqref{eq:d_answer}
 در گام سوم الگوریتم و تعویض گام‌های ۵ و ۶ برتری دارد. چرا که در مقداردهی اولیه استفاده شده برای $R$ از اطلاعات موجود در تمام داده‌ها از جمله نمونه‌های آزمون نیز استفاده شده است حال آن‌که مقداردهی $D$ با رابطه‌ی \eqref{eq:d_answer} تنها به نمونه‌های آموزش وابسته بوده و از اطلاعات بدون نظارت موجود در نمونه‌های آزمون بهره‌ای نمی‌برد. برای نشان دادن صحت این ادعا نتیجه دقت دسته‌بندی در هردوی این حالات سنجیده شده و نتایج آن در بخش  \ref{exp:jeac} گزارش شده است.
\section{جمع‌بندی}
در این بخش ابتدا نحوه‌ی استخراج ویژگی با شبکه‌های عصبی پیچشی ژرف شرح داده شد. سپس یک شبکه عصبی برای انجام پیش‌بینی صفت در مسئله یادگیری صفرضرب ارائه شد. پس از آن یک شبکه عصبی دیگر برای نگاشت تصاویر به فضای هیستوگرامی از دسته‌های دیده‌شده و انجام دسته‌بندی صفرضرب در این فضا ارائه شد. سپس  یک تابع مطابقت جدید برای مسئله یادگیری صفرضرب ارائه شد. برای بهره‌گیری مناسب از این تابع مطابقت یک خوشه‌بندی دقیق روی نمونه‌های آزمون مورد نیاز بود. به این خاطر، سپس یک الگوریتم خوشه‌بندی نیمه‌نظارتی که با فرض‌های مسئله‌ی یادگیری صفرضرب هم‌خوانی داشته باشد ارائه گردید. با فراهم آمدن این مقدمات یک روش برای دسته‌بندی صفرضرب با استفاده از تابع مطابقت و خوشه‌بندی پیشنهادی و یک نگاشت خطی از فضای توصیف دسته‌ها به فضای تصاویر ارائه شد. بعد از آن یک روش که یادگیری نگاشت و خوشه‌بندی در آن  به صورت توام انجام شود ارائه شد و در مورد نحوه‌ی بهینه‌سازی توابع پیشنهادی در این روش‌ها بحث شد.
%--------------------------section
