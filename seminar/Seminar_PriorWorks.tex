\section{کارهای پیشین}\label{review}
روش‌های مختلف برای یادگیری از صفر بر اساس اطلاعات جانبی مورد استفاده و نحوه برقراری ارتباط بین فضای نمونه‌ها و فضای اطلاعت جانبی با یک‌دیگر تفاوت دارند. علی‌رغم این تفاوت‌ها تلاش‌هایی برای ارائه یک صورت‌بندی یک‌پارچه از این مسئله صورت گرفته است. یک نحوه مدل‌سازی  یادگیری از صفر، آن طور که در \cite{hinton09} بیان شده، تبدیل آن به دو زیر مسئله است. مسئله اول یادگیری یک نگاشت از مجموعه تصاویر به یک فضای میانی که توصیف دسته‌ها در آن قرار دارند و مسئله دوم یادگرفتن یک دسته‌بند که اعضای فضای میانی را به برچسب‌ها دسته‌بندی کند. در این نحوه مدل‌سازی، فضای توصیف‌ها به همراه نگاشتی یک به یک به برچسب‌ها، داده‌شده فرض می‌شود. این درحالی‌ست که بسیاری از اوقات، توصیف‌ها به صورت خام قابل استفاده نیستند. برای مثال وقتی اطلاع جانبی از نوع متن است را در نظر بگیرید، فضای متون فضایی با بعد بسیار بالاست و لازم است که خود به یک فضای میانی نگاشته شود. از آن‌جا که یادگیری نگاشت از توصیف‌ها به فضای میانی ممکن است به صورت هم‌زمان و با اشتراک بعضی پارامترها با سایر قسمت‌های مدل یادگرفته شود، لازم است یادگیری این نگاشت را هم جزء چارچوب ارائه شده در نظر بگیریم. این نحوه‌ی مدل‌سازی یک چارچوب کلی برای بسیاری از روش‌های ارائه شده در یادگیری از صفر خواهد بود. در این بخش، با توجه به فراگیری این چارچوب ابتدا توصیف رسمی و نمادگذاری برای آن ارائه می‌شود. سپس روش‌های ذیل این چارچوب را مرور کرده و در پایان سایر روش‌ها را بیان می‌کنیم. 
 
 
 \subsection{نماد‌گذاری}\label{notaion}
 تصاویر را با 
 $x \in \mathbb{R}^d$
 نشان می‌دهیم که $d$ ابعاد داده را نشان می‌دهد. توصیف‌ها را با 
 $ c \in \mathbb{R}^a$
 نمایش می‌دهیم. $a$ ابعاد توصیف‌هاست. مجموعه دسته‌های دیده‌شده را با  $ \mathcal{S}$ و دسته‌های دیده‌نشده را با $ \mathcal{U}$ و مجموعه کل برچسب‌ها را با $ \mathcal{Y}$ 
 نشان می‌دهیم که
 $ \mathcal{Y} =  \mathcal{U} \cup \mathcal{S} $.
 همچنین   $s$ و $u$ به ترتیب تعداد هر کدام از دسته‌ها را نشان می‌دهد. $c^y$ که    $ y \in \mathcal{U} \cup \mathcal{S} $ بردار توصیف دسته $y$ را نشان می‌دهد.
   
    فرض می‌کنیم در زمان آموزش $ \{ (x^i, y^i) \}_{i=1}^{N_s} $ شامل $N_s$ تصویر از دسته‌های دیده شده به همراه برچسب  موجود است. 
     $X_s \in \mathbb{R}^{N_s \times d}$
  مجموعه تصاویر، $Y$ بردار برچسب‌ها با نمایش یکی یک
  \LTRfootnote{One-Hot Encoding}
   است. هم‌چنین توصیف‌های هر کدام از دسته‌های آموزش،
  $C_s \in \mathbb{R}^{s \times a}$
 نیز موجود است. $X_u$ و $C_u$ بطور مشابه برای دسته‌های آزمون تعریف می‌شوند.  $(X)_i$ سطر $i$م از ماتریس $X$ و $x_i$ درایه‌ی $i$م از بردار $x$ را نشان می‌دهد. 
 
 فضای میانی را با $ \mathcal{M} $ و ضرب داخلی آن را با  $\langle ., . \rangle $ نشان می‌دهیم. 
 $ \pi : \mathbb{R}^d \to \mathcal{M}$ 
 و
 $ \psi : \mathbb{R}^a \to \mathcal{M}$ 
نگاشت‌هایی از فضای تصاویر و توصیفات به این فضا هستند. 
یادگیری نگاشت‌های  $\pi$ و $\psi$ ممکن است به صورت مستقل از هم انجام شود یا اینکه هم‌زمان یادگرفته شوند. در نهایت باید دسته‌بندی از  $ \mathcal{M} $ به برچسب‌ها داشته باشیم:
 $ \phi : \mathcal{M} \to \mathcal{Y}$.
 در خیلی از موارد دسته‌بندی را تنها روی دسته‌های آزمون در نظر می‌گیریم، یعنی برد $\phi$ تنها $ \mathcal{U}$ را شامل می‌شود نه تمام برچسب‌ها را.
در ساده‌ترین حالت $\phi$ یک دسته‌بند نزدیک‌ترین همسایه در نظر گرفته می‌شود، یعنی برچسب نمونه آزمون  $x$ با رابطه \ref{inner} پیش‌بینی خواهد شد:
\begin{equation}\label{inner}
y^* = \argmax_{y \in \mathcal{U}} \langle \pi(x), \psi(c^y) \rangle
\end{equation}
البته این انتخاب برای  $\phi$ محدودیت‌های شناخته شده‌ای دارد. از جمله این که تمامی ابعاد از اهمیت یکسانی برخوردار هستند، درحالی‌که ممکن است بعض ویژگی‌ها قابلیت جداسازی بهتری داشته باشند. 

چارچوب فوق را می‌توان به روش‌های احتمالی هم تعمیم داد، به این صورت که $\pi$ و $\psi$ به صورت توزیع‌های احتمال شرطی تغییر پیدا می‌کنند. این تعمیم به صورت دقیق‌تر در بخش \ref{prob} بررسی خواهد شد. 


\subsection{کران خطا}\label{bound}
تعریف و فرضیات یادگیری از صفر با حالت معمول دسته‌بندی متفاوت است. در نتیجه کران‌هایی که پایین بودن خطای دسته‌بندی را با استفاده تعداد محدودی نمونه ضمانت می‌کنند در اینجا قابل به کار بردن نیستند. برای ارائه کران‌های خطای دسته‌بندی از صفر فرض‌های ساده‌کننده‌ای به مسئله اضافه شده است. برای این منظور فرض می‌شود که یادگیری نگاشت $\psi$ مستقل از $\pi$ انجام شده و رابطه بین توصیف‌ها و برچسب دسته‌ها رابطه‌ای یک به یک است. با این دو فرض می‌توان $\psi(c^y) $ را \emph{ امضای}  دسته‌ی $y$ نامید. 

در \cite{hinton09} با فرض دودویی بودن هر بعد از امضای دسته‌ها، کرانی بر اساس فاصله همینگ 
\LTRfootnote{Hamming}
میان امضای دسته‌ی صحیح و مقدار پیش‌بینی شده ارائه می‌شود. در \cite{emb15} از نتایج مشابه در حوزه تطبیق دامنه برای کران‌دار کردن خطا استفاده ارائه شده است و کران بر اساس تفاوت توزیع‌های داده‌های آموزش و آزمون به دست آمده است. در آن نوشتار راهی برای تخمین تفاوت این دو توزیع در حالت کلی ارائه نمی‌شود. تنها به دو حالت حدی اشاره می‌شود که در صورت یکسان بودن توزیع‌ها، کران ارائه شده همان کران مشهور VC \cite{vapnik} خواهد بود. هم‌چنین درحالتی که امضای دسته‌ها بر هم کاملا عمود باشد کران برای احتمال خطا بزرگتر از یک شده و اطلاعاتی در بر ندارد. 
\subsection{پیش‌بینی ویژگی}
همان‌طور که در بخش \ref{intro} اشاره شد، بردار ویژگی مرسوم‌ترین نوع توصیف دسته‌هاست. نخستین کارها روی یادگیری از صفر در بینایی ماشین \cite{lampert09, farhadi09}،
روش پیش‌بینی مستقیم ویژگی‌ها را پیشنهاد داده‌اند. در این حالت سعی می‌شود بردار ویژگی از روی تصویر ورودی بازسازی شود. آن‌گاه از میان دسته‌های دیده نشده، دسته‌ای که بردار ویژگی‌اش بیشترین مشابهت را با بردار پیش‌بینی شده دارد به عنوان برچسب معرفی می‌شود. با ادبیات چارچوب معرفی شده، این روش این گونه توصیف می‌شود که فضای میانی  $ \mathcal{M} $ همان فضای بردار ویژگی در نظر گرفته شده است در نتیجه نگاشت $\psi$ نگاشت همانی است و هدف تنها یادگرفتن نگاشت $\pi$ است. اهمیت این روش‌ها از یک طرف بخاطر داده‌های بسیاری است که با فراداده‌ها \LTRfootnote{Meta-data} و دنبالک‌ها \LTRfootnote{Tag} همراه شده‌اند که به صورت بردار ویژگی قابل مدل‌سازی هستند. دلیل دیگری برای اهمیت این روش‌ها این است که در مواردی هم که توصیف‌ها از نوع بردار ویژگی نیستند، ابتدا $\psi$ به صورت مستقل یادگرفته می‌شود و بعد از آن با در نظر گرفتن   $ \psi(c^x) $ بعنوان بردار ویژگی دسته‌ها، مسئله به حالت مورد بحث این بخش تبدیل خواهد شد.  

 
 اگر ویژگی‌ها دودویی باشند، این مسئله را می‌توان نوعی دسته‌بندی چند برچسبی \LTRfootnote{Mulit-label Classification} دانست که مدت زیادی است در حوزه یادگیری ماشین مورد مطالعه قرار گرفته است \cite{multilabel}. البته دسته‌بندی چندبرچسبی با یادگیری از صفر از طریق پیش‌بینی ویژگی تفاوت‌هایی دارد. در اولی خروجی الگوریتم یک بردار از برچسب‌هاست است که ترکیب‌های مختلف از وجود یا عدم وجود هر برچسب برای آن ممکن است، در دومی خروجی نهایتا یک برچسب از دسته‌های دیده نشده است و بردار ویژگی یک مقدار میانی برای رسیدن به این خروجی است. هم‌چنین همه ترکیب‌ها از ویژگی‌ها مجاز نیستند و تنها به تعداد دسته‌ها بردار ویژگی معتبر وجود دارد. در صورتی که ویژگی‌ها پیوسته باشند مسئله پیش‌بینی آن‌ها می‌تواند به صورت یک مسئله رگرسیون در نظر گرفته شود که برای در نظر گرفتن ارتباط ویژگی‌های مختلف باید با مدل‌های 
 رگرسیون ساختاریافته  \cite{elements} حل شود. روش‌های معمول رگرسیون مانند فرآیند گاوسی هر ویژگی را به صورت جداگانه یاد گرفته و ارتباط میان ابعاد در نظر گرفته نخواهد شد \cite{mohamed13}. مانند حالت دودویی این مسئله با یادگیری از صفر متفاوت است، در این مسئله به دنبال خطای کمتر در ویژگی‌های پیش‌بینی شده هستیم درحالی‌که در مسئله یادگیری از صفر این خطا اهمیتی ندارد و الگوریتم با دقت برچسب‌گذاری سنجیده می‌شود. 
\subsubsection{روش‌های احتمالی}\label{prob}

 
یکی از نخستین روش‌های پیش‌بینی ویژگی در \cite{lampert09} ارائه شده است. فرض کنید در زمان آموزش نمونه‌های 
$ \{ (x_i, y_i) \}_{i=1}^{N_s} $ 
به همراه بردار ویژگی دسته‌های آموزش  $C_y$ در اختیار قرار گرفته است. در نسخه اول این روش که DAP
\LTRfootnote{Direct Attribute Prediction}
 نام دارد استفاده از داده‌های آزمون تنها به صورت یادگیری دسته‌بندهایی برای هر یک از ویژگی‌هاست. این یادگیری با فرض استقلال ابعاد ویژگی‌ها انجام می‌شود، یعنی 
$P(c|x) = \prod_{i=1}^d P(c_i|x) $.
و هر یک از $P(c_i|x) $ها با یک رگرسیون منطقی 
\LTRfootnote{Logistic Regression}
روی کل داده‌ها (مستقل از برچسب آن‌ها) تخمین زده می‌شود. همچنین احتمال پیشین وقوع هر یک از ویژگی‌ها، $ P(c_i)$، به صورت تجربی
\LTRfootnote{Emprical}
 با توجه به تعداد وقوع تعیین می‌شود. رابطه بین توصیف‌ها و برچسب‌ها قطعی در نظر گرفته شده است. یعنی 
 $P(u|c) = \frac{p(u)\mathbb{I}(c = c^u) }{p(c^u)}$
 که $ \mathbb{I}(t) $ وقتی که شرط $t$ برقرار باشد برابر $1$ و در غیر این صورت صفر است. 
  در نهایت احتمال پسین هرکدام از برچسب‌های آزمون $u \in \mathcal{U}$ از این رابطه بدست می‌آید:
\begin{equation}
P(u | x ) = \sum_{c} P(u | c)P(c|x) = \frac{P(u)}{P(c^u)} \prod_{i=1}^a P(c^u_i|x) \propto \prod_{i=1}^a \frac{P(c^u_i|x)}{P(c^u_i)}
\end{equation}
مقدار صورت در این رابطه همان‌طور که گفته شد از داده‌های آموزش تخمین زده می‌شود و مخرج که احتمال پیشین رخ‌داد هر ویژگی است به صورت تجربی محاسبه می‌شود.
در نسخه دیگر این روش که IAP
\LTRfootnote{Indirect Attribute Prediction}
 نام دارد تخمین  $P(c_i|x) $ تغییر داده می‌شود؛ به این صورت که ابتدا یک دسته‌بند چند دسته‌ای یعنی $P(y_k |x)$ روی داده‌ها یاد گرفته می‌شود و سپس رابطه ویژگی‌ها و برچسب‌ها به صورت قطعی مدل می‌شود:
\begin{equation}
P(c_i | x) = \sum_{k=1}^s P(y_k | x) \mathbb{I}(c_i = c^{y_k}_i)
\end{equation}
در نهایت در هر دو روش برچسب نهایی با تخمین MAP 
\LTRfootnote{Maximum a Posteriori}
از رابطه زیر تعیین می‌شود:
\begin{equation}
\hat{y} = \argmax_{u \in \mathcal{U}} P(u|x) =  \argmax_{u \in \mathcal{U}} \prod_{i=1}^a \frac{P(c_i^u | x)}{P(c_i^u)}
\end{equation}

علاوه بر این دو نسخه، این روش به حالت‌های دیگری هم توسعه داده شده است. برای مثال در \cite{suzuki14} وزن‌دهی متفاوت برای مدل‌سازی اهمیت هر کدام از ویژگی‌ها به مدل اضافه شده است. این روش دو کمبود مهم دارد، اول این که فرض استقلال میان ویژگی‌ها بسیار غیر واقعی است. برای مثال ویژگی‌های بصری خاک و صحرا وابستگی واضحی وجود دارد. مشکل دوم این است که  یادگیری دسته‌بندها برای هر ویژگی بدون توجه به مراحل بعدی و نتایج سایر دسته‌‌بندهاست؛ درحالی‌که خروجی هر دسته‌بند در دسته‌بندی دیگری استفاده خواهد شد و معیار ارزیابی،  عمل‌کرد خطای دسته‌بند دوم است، یعنی خطای پیش‌بینی ویژگی‌ها به طور مستقیم اهمیت ندارد. نویسندگان \cite{ ajoint11} برای حل این مشکل پیشنهاد می‌کنند فرض یک به یک بودن نگاشت بین بردارهای ویژگی و برچسب‌ها را در نظر نگیریم. در این روش پیش‌بینی ویژگی‌ها مانند مدل DAP با رگرسیون منطقی انجام می‌شود با این تفاوت که یادگیری پارامترهای آن‌ها و  $\phi$ به صورت مشترک انجام می‌شود. $\phi$ یک نگاشت خطی در نظر گرفته می‌شود: 
  $\phi(\pi(x)) = R\pi(x) $. 
 دو محدودیت روی مقادیر R اعمال می‌شود. یک محدویت سطری و یک محدودیت ستونی. محدودیت سطری مانع از این می‌شود که فاصله همینگ سطرها از حدی کمتر بشود. دقت کنید که در یک دسته‌بند خطی به شکل بالا، هر سطر را می‌توان مرکز ثقل نمونه‌های دسته‌ی متناظر آن سطر تعبیر کرد. در نتیجه این محدودیت تضمین می‌کند که بردار ویژگی نماینده هر دسته با دسته‌های دیگر متفاوت باشد. محدودیت ستونی یک مقدار حداکثری برای همبستگی میان ستون‌ها در نظر می‌گیرد تا به این صورت اطلاعات تکراری در ویژگی‌ها وجود نداشته باشد. نویسندگان این مقاله استدلال می‌کنند که با این دو محدودیت باعث حذف ویژگی‌های تکراری و ویژگی‌های غیر بصری (مانند بدبو بودن) خواهد شد.
 
نویسندگان \cite{ topicmodel} برای در نظر گرفتن ارتباط بین ویژگی‌ها و ارتباط ویژگی‌ها با برچسب نهایی روش‌های مدل‌سازی موضوع \LTRfootnote{  Topic Modeling} را از حوزه یادگیری در متن اقتباس می‌کنند. همچنین  نویسندگان \cite{ unified13} برای این کار یک چارچوب بر اساس مدل‌های گرافی احتمال معرفی می‌کنند. در این چارچوب یک شبکه بیزی\LTRfootnote{  Baysian Network}  برای مدل کردن این روابط در نظر گرفته می‌شود و ساختار آن که نشان‌دهنده وابستگی یا استقلال ویژگی‌ها با هم یا با برچسب است، با کمک روش‌های یادگیری ساختار 
\LTRfootnote{Structure Learning}
شناخته می‌شود. 


\subsubsection{نگاشت‌های خطی}\label{linear}
چند روش اخیر وجود دارد که علی‌رغم ساده بودن نتایج بهتری از روش‌های قبلی کسب کرده‌اند. در این روش‌ها  نگاشت $\psi$ همانی، دسته‌بند $\phi$ دسته‌بند نزدیک‌ترین همسایه و نگاشت $\pi$ خطی (به صورت $\pi(x) = xW$) در نظر گرفته شده‌اند. اما معرفی توابع هزینه یا جمله‌های منظم‌سازی 
\LTRfootnote{Regularization  Term}
هوشمندانه‌تر باعث شده که نتایج بهتری به دست بیاورند. یکی از این روش‌ها که در \cite{ akata13} معرفی شده، تابع هزینه‌ای ارائه می‌دهد که هم خطای دسته‌بندی، هم خطای پیش‌بینی ویژگی‌ها را در نظر می‌گیرد. این تابع هزینه چنین شکلی دارد:
\begin{align}
L(W) = \frac{1}{N_s} \sum_{n=1}^{N_s} \lambda_{r_\Delta (x_n, y_n)} \sum_{y \in \mathcal{Y}} \max (0, \mathit{l}(x_n, y_n, y) ) \\
\mathit{l}(x_n,y_n,y) = \mathbb{I}(y \neq y_n) + F(x_n, c_y; W) - F(x_n, c_{y_n};W)
\end{align}
که در آن 
$ r_\Delta (x_n, y_n) =  \sum_{y \in \mathcal{Y}} \mathbb{I}(\mathit{l}(x_n, y_n, y)  > 0) $،
$F$ 
یک تابع رتبه‌بندی 
 و $\lambda_k$ یک تابع نزولی از $k$ است. این تابع، پیش‌بینی اشتباه ویژگی‌ها را  این گونه جریمه می‌کند که به ازای برچسب نادرستی که رتبه بالاتری از برچسب صحیح در دسته‌بندی دریافت کرده، جریمه‌ای متناسب با امتیاز برچسب ناصحیح در نظر گرفته می‌شود.ضریب نزولی $\lambda_k$ میزان جریمه را برای برچسب‌های غلط در رتبه‌های بالا بیشتر در نظر می‌گیرد.

یک روش دیگر که در \cite{ emb15} ارائه شده، نگاشت‌های مشابهی را استفاده می‌کند. همچنین تابع هزینه آن شکل ساده نرم ۲ را دارد. مسئله‌ی بهینه‌سازی تعریف شده به این شکل است:
\begin{equation} 
\minimize_{W \in \mathbb{R}^{d \times a}} \normf{X_s WC_s^T-Y} + \Omega(W) \label{embopt}
\end{equation}
که $\Omega(W)$ یک جمله منظم‌سازی است که به این صورت تعریف می‌شود:
\begin{align}\label{embreg}
 \Omega(W;X_s, C_s) = \gamma \normf{WC_s^T} + \lambda \normf{XW} + \beta \normf{W} 
\end{align}
$\gamma $، 
$\lambda$ و 
$\beta$
فراپارامترهایی هستند که اهمیت هر یک از جملات را تعیین می‌کنند. 
 تابع هزینه فوق تنها دسته‌بندی اشتباه را جریمه می‌کند. مناسب نبودن تابع هزینه نرم ۲ برای خطای دسته‌بندی مسئله‌ای شناخته شده در یادگیری ماشین است و عمل‌کرد خوب این تابع در این روش شاید در نگاه اول عجیب بنظر برسد. اگر در جمله منظم‌سازی تعریف شده دقت کنیم این مسئله روشن‌تر خواهد شد. علت نامناسب بودن تابع هزینه نرم ۲ این است که حتی دسته‌بندی‌های صحیح را اگر مقداری غیر از مقدار تعیین شده (معمولا یک) داشته باشند، به اندازه فاصله‌شان از این مقدار جریمه می‌کنید. اما جمله منظم‌سازی تعریف شده اصولا مانع بزرگ شدن مقدار پیش‌بینی شده خواهد شد. جمله اول در معادله \eqref{embreg} را می‌توان اندازه بردار تصویر متوسط برای هر دسته دانست. جمله دوم مقدار بردار ویژگی پیش‌بینی شده برای هر دسته است و جمله سوم هم که یک جمله معمول است که پارامترهای نگاشت را کنترل می‌کند. در زمان آزمون برای نمونه $x$ مقدار $xWC_u$ را محاسبه کرده و دسته‌ای که درایه‌ی متناظرش بیشترین مقدار را دارد به عنوان پیش‌بینی معرفی می‌کنیم. یک ویژگی این روش این است که با انتخاب $ \beta = \gamma \lambda$ در معادله \eqref{embreg} بهینه‌سازی معادله \eqref{embopt} جواب بسته خواهد داشت؛ در نتیجه زمان اجرای این روش بسیار کمتر از سایر روش‌هایی است که مرور شد. 

یک روش خطی دیگر که مستقیم از ویژگی‌ها استفاده نمی‌کند، کاری است که در \cite{ devise} معرفی شده است. این روش تنها از نام هر دسته به عنوان توصیف بهره می‌برد. در این روش نام‌ها، مستقل از اطلاعات دیگر مسئله، به بردارهایی نگاشته می‌شوند، بردارهای حاصل را می‌توان مانند بردار ویژگی در سایر مسائل به حساب آورد؛ در نتیجه این روش را ذیل عنوان پیش‌بینی ویژگی مرور می‌کنیم. این روش ابتدا برای بدست‌آوردن بردارهای مربوط به نام‌ها از مدل مشهور 
\lr{word2vec}  \cite{word2vec} 
با پیش‌آموزش روی مقالات ویکی‌پدیای انگلیسی استفاده می‌کند، هم‌چنین برای ویژگی‌های تصویر از شبکه عصبی برنده چالش
\lr{ILSVRC 2012}،
\lr{AlexNet}
استفاده می‌کند. \footnote{ استفاده از مقادیر نورون‌های لایه چگال اول شبکه‌های عصبی به عنوان ویژگی‌های بصری در بسیاری از روش‌های دیگر نیز صورت گرفته است؛ در نتیجه این قسمت جزیی از نگاشت $\pi$ در نظر گرفته نمی‌شود، بلکه این مقادیر را به عنوان مجموعه تصاویر ($X$) تلقی می‌کنیم. }
این روش نیز $\pi$ را خطی و دسته‌بند $\phi$ را نزدیک‌ترین همسایه در نظر می‌گیرد. تابع هزینه مورد استفاده از این روش یک تابع هزینه‌ی رتبه‌بند است به این معنی که مانند  \cite{ akata13} به ازای  برچسب‌هایی که امتیاز بیشتری نسبت به برچسب صحیح کسب کرده‌اند، جریمه در نظر می‌گیرد:
\begin{equation}
 L((x_n, y_n);W) = \sum_{y\neq y_n} \max(0, \text{magrin} - x_nWc_{y_n} + x_nWc_y) 
\end{equation}

\subsection{یادگیری دسته‌بند}\label{learnclassifer}
روشی ارائه شده در \cite{ mohamed13} برای نخستین بار، از استفاده از متونی در مورد هر دسته را به عنوان توصیف در نظر گرفته و مجموعه دادگانی برای این موضوع فراهم می‌آورد. در این روش هدف یافتن یک دسته‌بند دودویی (رد یا قبول) برای هر دسته از روی توصیف متنی آن است. با توجه به این که دسته‌بند مورد نظر خطی فرض شده است، می‌توان این روش را این گونه هم تعبیر کرد که به دنبال نگاشتن متون توصیف‌کننده به فضای تصاویر است. یعنی فضای میانی فضای تصاویر در نظر گرفته شده و پس از نگاشتن توصیف‌ها به آن فضا برچسب‌ها با دسته‌بند نزدیک‌ترین همسایه مشخص می‌شود. این روش برای یافتن دسته‌بندهای دسته‌های دیده نشده، همزمان دو رویکرد رگرسیون احتمالی
\LTRfootnote{Probabilistic Regression}
 و تطبیق دامنه را استفاده می‌کند. طبق نمادگذاری تعریف شده  $c_u$ یک توصیف برای دسته دیده نشده  و $\psi(c_u)$ نگاشت آن به فضای تصویر (یا به تعبیر دیگر دسته‌بند دسته‌ی مربوط به دسته‌ی $c_u$) است. ماتریس تطبیق دامنه $W$ با استفاده از نمونه‌های آموزش طوری یادگرفته شده است که اگر $c$ و $x$ متعلق به یک دسته باشند، $c^TWx$ از آستانه‌ای مانند $t$ بیشتر است. مسئله بهینه‌سازی تعریف شده برای محاسبه  $\psi(c_u)$ به این صورت است:
\begin{align}\label{elhos}
\psi(c_u) &= \argmin_{h, \zeta_i} \{ h^Th  - \alpha c_u^TWh - \beta \ln(P(h|c_u)) + \gamma \sum \zeta_i \} \\
s.t: & -(h^T)(X_s)_i \geq \zeta_i, \quad \zeta_i \geq 0, \quad i=1,\ldots, N_s  \nonumber \\
& c^TWc \geq t \nonumber
\end{align}
$\alpha$، $\beta$ 
و $\gamma$ فراپارامتر هستند. جمله اول در معادله \eqref{elhos} یک عبارت منظم‌سازی است، جمله دوم مربوط به رویکرد تطبیق دامنه است که دسته‌بند تخمین زده شده را $c_y^TW$ می‌داند و جمله سوم مربوط به رگرسیون احتمالی است که دسته‌بند را به سمت عبارت حاصل از این رگرسیون سوق می‌دهد. محدودیت روی $\zeta_i$ها اجبار می‌کند که این دسته‌بند به نمونه‌ای از دسته‌های آموزش برچسب مثبت اختصاص ندهد. نویسندگان این پژوهش یک نسخه با امکان استفاده از هسته نیز از کار خود در 
\cite{elhoseiny2015} 
ارائه می‌دهند. بر مبنای چارچوب همین پژوهش در  \cite{ba2015} از شبکه‌های عصبی برای تخمین زدن دسته‌بند برای دسته‌های دیده نشده استفاده شده است. به این صورت که یک شبکه عصبی پیش‌آموزش دیده برای استخراج ویژگی از تصاویر استفاده می‌شود تا ابعاد یا تعداد پارامترهای دسته‌بندی که لازم است تخمین زده شود کم شود. آن‌گاه از یک شبکه عصبی دیگر برای نگاشت متن به برداری در فضای ویژگی‌های تصویر (یا همان دسته‌بند دسته‌ی مربوط به آن متن) استفاده می‌شود. این پژوهش همچنین دسته‌بند پیچشی \LTRfootnote{Convolutional} را معرفی می‌کند. فرض کنید 
$x_i'$
 مقادیر ویژگی‌نگار 
 \LTRfootnote{Feature Map} $i$م
  آخرین لایه پیچشی یک \lr{ CNN}  \LTRfootnote{convolutional Neural Network} با $K$ ویژگی‌نگار، برای ورودی $x$ باشد. در این صورت یک دسته‌بند پیچشی مانند   $r$ در حقیقت یک صافی پیچشی
\LTRfootnote{Convolotional Filter}
است و ابعاد آن برابر 
  $ K \times s \times s$
  است که $s$ اندازه صافی است که یک فراپارامتر است. برچسبی که $r$ برای نمونه $x$ پیش‌بینی می‌کند از این رابطه به دست خواهد آمد:
\begin{equation}
\hat{y} = o \big ( \sum_i r_i \ast r_i \big )
\end{equation}
که $o(.)$ یک تابع ادغام \LTRfootnote{Pooling} است که به طور معمول در شبکه‌های پیچشی مورد استفاده قرار می‌گیرد. یادگیری $r$ به این صورت خواهد بود که رابطه بالا کمترین خطا را در پیش‌بینی برچسب روی نمونه‌های آموزش داشته باشد. خطای در نظر گرفته شده برای بدست آوردن $r$، آنتروپی متقابل 
\LTRfootnote{Cross-Entropy}
است. 

یک روش‌دیگر که از چنین رویکردی استفاده می‌کند در \cite{ costa} معرفی شده است. در این روش توصیف هردسته، پارامترهای یک  دسته‌بند برای آن در نظر گرفته شده. دسته‌بند یک دسته دیده نشده بر حسب جمع وزن‌دار دسته‌های دیده شده بیان می‌شود. وزن‌های این جمع وزن‌دار از امتیاز شباهت دسته‌ها با هم بدست می‌آید. امتیاز شباهت، با استفاده از تعداد رخ‌داد همزمان نام‌های برچسب‌ها در یک مجموعه متن سنجیده می‌شود. نویسندگان این پژوهش همچنین مسئله یادگیری از صفر چندبرچسبی را معرفی می‌کنند. در این چارچوب برچسب‌ها یا ویژگی‌‌ها به صورت یک برچسب که یک دسته‌بند برای آن موجود است در نظرگرفته می‌شود و با استفاده از روشی که معرفی شد می‌توان از آن‌ها در به دست آوردن دسته‌بندی برای یک برچسب بی‌نمونه استفاده کرد. 


\subsection{نگاشت به فضای دسته‌های دیده شده}\label{toseen}
یک انتخاب محبوب برای فضای میانی $\mathcal{M}$ فضایی با ابعاد تعداد دسته‌های دیده شده است. در نگاشت به این فضا سعی می‌شود تصاویر یا توصیفات دسته‌های آزمون  بر حسب نسبت‌هایی از دسته‌های دیده بیان شود. یکی از روش‌هایی که از چنین نگاشتی استفاده می‌کند، روشی است که نویسندگان \cite{ convex} در ادامه کار پیشین خود  \cite{ devise}، که در بخش \ref{linear} مرور شد، ارائه می‌دهند. در این روش بجای استفاده از مقادیر نورون‌های میانی شبکه \lr{AlexNet} از خروجی آخرین لایه این شبکه، یعنی لایه‌ی \lr{softmax} استفاده می‌کنند. این لایه به تعداد دسته‌های دیده شده نورون دارد و تعبیر مقادیر این لایه، امتیازی است که شبکه برای تعلق تصویر به هر دسته ‌می‌دهد. پس بدست آوردن این نمایش برای تصویر در فضای میانی، این نمایش به فضای توصیف‌ها که بردارهای متناظر با نام دسته‌هاست نگاشته می‌شود؛ به این صورت که بردارهای نام دسته‌های دیده شده با این وزن‌ها با یکدیگر جمع شده و حاصل با استفاده از دسته‌بندی نزدیک‌ترین همسایه برچسب یک دسته دیده نشده را معین می‌کند. 

یک روش اخیر معرفی شده در \cite{ sse} که نتایج را به طرز قابل توجهی بهبود داده است نیز از این فضا به عنوان فضای میانی استفاده می‌کند. نگاشت بردارهای ویژگی به این فضا با حل معادله زیر انجام می‌شود:
\begin{equation} \label{sse_att}
\psi(c) = \argmin_{ \boldsymbol{\alpha} \in \Delta^{s} } \big \{ \gamma \norm{\boldsymbol{\alpha}}^2 + \norm{c - \sum_{y \in \mathcal{S}} c_y \alpha_y}^2 \big \}
\end{equation}

که 
\boldmath{$\alpha$}
برداری به اندازه تعداد دسته‌های دیده است و هر درایه‌ی $\alpha_y$ آن نسبت دسته $y$ را در تشکیل دسته دیده نشده تعیین می‌کند. $\Delta^{s}$ تک‌جهتی 
\LTRfootnote{Simplex} $s$
 بعدی  است، یعنی این نگاشت در حقیقت یک بافت‌نگاره 
 \LTRfootnote{Histogram}
از دسته‌های دیده شده تولید می‌کند. نگاشت تصاویر به این فضا از یک مسئله بهینه‌سازی محدودیت‌دار بدست می‌آید. برای هر بعد از این نگاشت، یک نگاشت دیگر ویژه هر دسته دیده شده یادگرفته می‌شود که میزان حضور آن دسته را در تصویر مشخص می‌کند.
\subsection{یادگیری نگاشت‌ها از دو دامنه}\label{joint_embedding}
در اکثر روش‌هایی که تا کنون مرور شد، فضای میانی همان فضایی که توصیف‌ها در آن هستند در نظر گرفته می‌شد یا این‌که نگاشت از دامنه توصیف‌ها به طور مستقل از مسئله (برای مثال با استفاده از اطلاعات یک مجموعه متن) یاد گرفته می‌شد؛ چنین رویکردی دارای این ضعف آشکار است که نمایش بدست آمده برای برچسب‌ها جدا کننده‌
\LTRfootnote{Discriminative}
 نباشد. از میان روش‌هایی که دیدیم  \cite{ajoint11, unified13} با پیچیده‌تر کردن ساختار دسته‌بند $\phi$ یا به عبارتی به هم زدن رابطه \emph{ امضا بودن} بردارهای ویژگی برای دسته‌ها سعی در حل این مشکل داشتند. یک روش اخیر \cite{ semi15} با الهام از راه‌کارهای یادگیری نیمه‌نظارتی روشی برای یادگیری  یک دسته‌بند چند دسته‌ای و نگاشت‌های برای برچسب‌ها به صورت هم‌زمان ارائه می‌دهد. در این روش دسته‌بند یادگرفته شده برای تمامی دسته‌ها (و نه تنها برای دسته‌های آزمون) است. توصیف‌هایی که برای دسته‌ها وجود دارد می‌توانند بعنوان یک مقدار پیشین \LTRfootnote{prior} برای نمایش برچسب‌ها در فضای میانی در نظر گرفته شوند. این پژوهش هم‌چنین تاثیر ابعاد فضای میانی را روی دقت دسته‌بندی برای دو مجموعه داده بررسی می‌کند، در ابعاد بررسی شده (بین ۲۰ تا ۱۰۰ بعد) دقت تابعی صعودی از ابعاد است. ابعاد تصاویر در این بررسی ۲۰۰۰ برای یک مجموعه داده و ۱۵۰۰ برای مجموعه داده دیگر بوده است.
 %%%%%%%%%%%%%%%%%%%%%%%%%%% qoute loss function?
رویکردی مشابه در \cite{ li15max} از همین گروه ارائه شده که چارچوب مسئله یادگیری نیمه‌نظارتی را به یادگیری از صفر تبدیل می‌کند با این تفاوت که نمایش برچسب‌ها در فضای میانی ثابت فرض می‌شوند و بردارهای مربوط به نام دسته‌ها هستند. 


\subsection{سایر روش‌ها}\label{other}
روشی که در \cite{ agnostic}  معرفی شده و تا کنون بهترین نتایج را روی مجموعه‌دادگانی که توصیف دسته‌ها از نوع بردار ویژگی بدست آورده از رویکردی کاملا متفاوت بهره می‌برد. در این روش تنها یک دسته‌بند ساخته می‌شود که دو ورودی دارد: یک تصویر و یک توصیف و مقدار خروجی که مقداری دودویی است مشخص می‌کند که تصویر و توصیف ورودی متعلق به یک دسته هستند یا خیر. $y^{xc}$ را به صورت یک متغیر دودویی که اگر $x$ و $c$ متعلق به یک دسته باشند یک و در غیر این صورت صفر است، تعریف می‌کنیم. آماره‌ی کافی برای دسته‌بند مورد نظر $ P(y^{xc} | x,c)$ است. برای تخمین این احتمال از دو متغیر نهان کمک گرفته می‌شود. این متغیرها یک زنجیر مارکف تشکیل می‌دهند که رابه \eqref{e.markov} نشان داده شده است. 
\begin{align} \label{e.markov}
X \leftrightarrow Z^{(x)} \leftrightarrow Y  \leftrightarrow Z^{(c)} \leftrightarrow C.
\end{align}
با توجه به \eqref{e.markov} مشخص است که با داشتن برچسب دسته‌ها متغیرهای تصادفی تصاویر و توصیف‌ها و نمایش نهان آن‌ها از یک‌دیگر مستقل هستند در نتیجه احتمال پسینی به این صورت جدا می‌شود: 
\begin{equation}
p(y^{(xc)}, {z}^{(x)}, {z}^{(c)} \mid {x}, {c}) = p(y^{(xc)} \mid {z}^{(x)}, {z}^{(c)}) p({z}^{(x)}, {z}^{(c)} \mid {x}, {c}) \nonumber
\end{equation}
هم‌چنین فرض می‌شود که در غیاب اطلاعی در مورد برچسب‌ها نمایش‌های نهان از هم مستقل هستند، یعنی
  $p({z}^{(x)}, {z}^{(c)}) \approx p({z}^{(x)})p({z}^{(c)})$
نهایتا دسته‌بندی با میانگین‌گیری روی متغیرهای نهان مقدور خواهد بود:
\begin{align} \label{eqn:p} 
p( y^{(xc)} \mid {x}, {c})
=\int\int p({z}^{(x)}|{x})p({z}^{(c)}|{c})p(y^{(xc)}|{z}^{(x)}, {z}^{(c)})d{z}^{(x)}d{z}^{(c)} 
%\nonumber%=\left[{z}^{(s)}\right]^T{W}{z}^{(t)},
\end{align}
در ادامه این روش از محاسبه این انتگرال صرف‌نظر شده و یک کران پایین از آن جایگزین آن شده است:
\begin{equation}\label{eqn:lb}
\log p( y^{(xc)} \mid x, c) 
 \geq \max_{{z}^{(x)},{z}^{(c)}}  \log p({z}^{(x)}|x)p({z}^{(x)}|c)p(y^{(xc)}|{z}^{(x)}, {z}^{(c)})
\end{equation}
 در \cite{Akata2015} انواع نگاشت‌های مختلفی که برای برچسب‌ها با استفاده از روش‌های غیرنظارتی وجود دارد بررسی و ارزیابی می‌شود. هم‌چنین عمل‌کرد ویژگی‌های مختلف تصویر در یادگیری از صفر بررسی می‌شود. نویسندگان این پژوهش برای مقایسه این نگاشت‌ها از آن‌ها در روشی که خود معرفی کردند \cite{ akata13} و ما آن را در بخش \ref{linear} شرح دادیم استفاده کرده‌اند. 
 
 در \cite{Kodirov2015} برای اولین بار یادگیری از صفر به صورت یک مسئله تطبیق‌دامنه‌ی بدون نظارت از دامنه داده‌های آموزش به دامنه داده‌های آزمون مدل شده است. صورت مسئله یادگیری از صفر با مسئله تطبیق دامنه متفاوت است چرا که دامنه مقصد در مسئله یادگیری از صفر مجموعه برچسب‌هایی متفاوت از دامنه مبدا دارد. برای تبدیل این مسئله به یک مسئله تطبیق دامنه، نویسندگان پژوهش مسئله نگاشت تصاویر آزمون به فضای میانی (برای مثال فضای بردارهای ویژگی) را در نظر می‌گیرند. مسئله نگاشت به این فضا را می‌توان یک مسئله تطبیق دامنه در نظر گرفت چرا که داده‌های آموزش و آزمون هر دو باید به این فضا نگاشته شوند. این مسئله جدید یک مسئله تطبیق دامنه بدون نظارت است چرا که نمونه‌های دامنه مقصد برچسبی ندارند. برای حل این مسئله‌ی تطبیق دامنه فضای میانی، فضایی با ابعاد بالا در نظر گرفته شده است و از روش‌های نمایش تنک 
 \LTRfootnote{Sparse Coding}
و یادگیری واژه‌نامه برای یافتن نمایش دسته‌ها استفاده شده است. 
 
 
در \cite{ng13} توصیف دسته‌ها، نام برچسب‌ها در نظر گرفته شده و با استفاده از یک مدل پیش‌آموزش دیده شده، آن‌ها را به بردارهای ۵۰-بعدی تبدیل می‌کند. سپس تصاویر را با یک شبکه عصبی دو لایه به این فضا نگاشته و با روش نزدیک‌ترین همسایه برچسب را پیش‌بینی می‌کند. تفاوت این پژوهش با سایر پژوهش‌ها این است که دسته‌بندی نهایی را تنها روی دسته‌های دیده نشده در نظر نمی‌گیرد بلکه روی کل دسته‌ها در نظر گرفته و روشی برای تشخیص این که آیا نمونه آزمون می‌تواند به دسته‌های دیده شده تعلق داشته باشد یا نه ارائه می‌دهد.

یک راه‌حل مبتنی بر جنگل‌های تصادفی \LTRfootnote{Random Forest} در \cite{ jayaraman14} ارائه می‌شود. این روش در مرحله تشخیص ویژگی، برای هر ویژگی یک \lr{ SVM}  به طور مستقل یاد می‌گیرد. قسمت اصلی روش پیش‌نهادی در طراحی دسته‌بند $\phi$ است. این دسته‌بند با جنگل‌های تصادفی ساخته می‌شود اما از آن‌جایی که ویژگی‌های پیش‌بینی شده برای تصاویر احتمالا با بردار ویژگی توصیف کننده‌ی دسته تفاوت‌هایی دارد، اجازه پیگیری همزمان چند مسیر در جنگل تصادفی داده می‌شود تا این عدم قطعیت در نظر گرفته شود. 




%----------------------------------- Remaining: Semantic Manifold Distance, Efficient Max-Margin Multi-Label Classification with Applications to Zero-Shot Learning
 

