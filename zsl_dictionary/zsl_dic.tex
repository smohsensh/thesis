%\documentclass[wcp,gray]{jmlr} % test grayscale version
\documentclass[wcp]{jmlr}

% The following packages will be automatically loaded:
% amsmath, amssymb, natbib, graphicx, url, algorithm2e

%\usepackage{rotating}% for sideways figures and tables
\usepackage{longtable}% for long tables

% The booktabs package is used by this sample document
% (it provides \toprule, \midrule and \bottomrule).
% Remove the next line if you don't require it.
\usepackage{booktabs}
% The siunitx package is used by this sample document
% to align numbers in a column by their decimal point.
% Remove the next line if you don't require it.
%\usepackage[load-configurations=version-1]{siunitx} % newer version
%\usepackage{siunitx}
%\usepackage{natbib}

% The following command is just for this sample document:
\newcommand{\cs}[1]{\texttt{\char`\\#1}}

\jmlrvolume{60}
\jmlryear{2016}
\jmlrworkshop{ACML 2016}

\title[Short Title]{Full Title of Article}

 % Use \Name{Author Name} to specify the name.
 % If the surname contains spaces, enclose the surname
 % in braces, e.g. \Name{John {Smith Jones}} similarly
 % if the name has a "von" part, e.g \Name{Jane {de Winter}}.
 % If the first letter in the forenames is a diacritic
 % enclose the diacritic in braces, e.g. \Name{{\'E}louise Smith}

 % Two authors with the same address
 % \author{\Name{Author Name1} \Email{abc@sample.com}\and
 %  \Name{Author Name2} \Email{xyz@sample.com}\\
 %  \addr Address}

 % Three or more authors with the same address:
 % \author{\Name{Author Name1} \Email{an1@sample.com}\\
 %  \Name{Author Name2} \Email{an2@sample.com}\\
 %  \Name{Author Name3} \Email{an3@sample.com}\\
 %  \Name{Author Name4} \Email{an4@sample.com}\\
 %  \Name{Author Name5} \Email{an5@sample.com}\\
 %  \Name{Author Name6} \Email{an6@sample.com}\\
 %  \Name{Author Name7} \Email{an7@sample.com}\\
 %  \Name{Author Name8} \Email{an8@sample.com}\\
 %  \Name{Author Name9} \Email{an9@sample.com}\\
 %  \Name{Author Name10} \Email{an10@sample.com}\\
 %  \Name{Author Name11} \Email{an11@sample.com}\\
 %  \Name{Author Name12} \Email{an12@sample.com}\\
 %  \Name{Author Name13} \Email{an13@sample.com}\\
 %  \Name{Author Name14} \Email{an14@sample.com}\\
 %  \addr Address}


 % Authors with different addresses:
  \author{\Name{Author Name1} \Email{abc@sample.com}\\
  \addr Address 1
  \AND
  \Name{Author Name2} \Email{xyz@sample.com}\\
  \addr Address 2
 }

%\editors{List of editors' names}

\begin{document}

\maketitle

\begin{abstract}
This is the abstract for this article.
\end{abstract}
\begin{keywords}
List of keywords
\end{keywords}

\section{Introduction}
Zero-shot learning is an extension to the conventional supervised learning scenario
that introduces task of recognizing instances from categories with no training sample.
 The problem addressed by zero-shot learning, rises naturally in practice wherever acquiring ample labeled instances
 is not feasible for all categories. Examples include large-scale and fine-grained classification.
To describe the task more precisely, in training phase labeled samples from some categories are provided,
these categories are called seen categories. Also for each category some sort of description is available.
Description may be human annotated attributes or derived from textual description available online.
There are also some other categories without labeled instances, these are called unseen categories.
 In test time, unlabeled instances should be classified into unseen classes.
 %In this setting, zero-shot learning mitigates the problem of acquiring labeled instances, which can be hard for novel, rare and fine grained categories.

Most existing methods for zero-shot learning use 
so that they're mapped near their true description and far from descriptions of other classes.


 In recent years, advances in deep convoloutional neural networks provides rich visual features with high discrimination capability.
 Thus there is usually a meaningful structure in visual features domain
that can be used to help classification be done more precisely, like in semi-supervised settings.
 In the previous works, most concentration has been on finding embeddings for visual features and little effort has been made to exploit unsupervised information in images domain.

 In this work
 %we first justify the claim made above by applying a simple clustering algorithm and reporting
%Rand Index measure between cluster assignments and ground truth labels. Motivated by the result,
 we propose a
  semi-supervised clustering algorithm to leverage labels available for seen classes to obtain more accurate cluster assignments.
 Then we use a simple dictionary learning method to map class descriptions to visual features, creating a set of landmarks in
 visual domain. These landmarks are used to label cluster centers driven from clustering algorithm. We argue that this learning
 scheme can mitigate domain shift problem \cite{eccv14} between seen and unseen categories and thus achieving higher classification accuracy.
We demonstrate this by carrying out extensive experiments on four benchmarks popular for zero-shot recognition.


\subsection{Subsection Title}
An figure in Fig.~\ref{fig:spiral}
\begin{figure}[htp]
\begin{center}
\includegraphics[width=0.5\textwidth]{../images/logo.pdf}
\caption{A spiral.}\label{fig:spiral}
\end{center}
\end{figure}

An example of citation~\cite{DBLP:conf/acml/2009}.

\acks{Acknowledgements should go at the end, before appendices and references.}

%\bibliographystyle{plain}
\bibliography{acml16}

\appendix

\section{First Appendix}\label{apd:first}

This is the first appendix.

\section{Second Appendix}\label{apd:second}

This is the second appendix.


\end{document}
